# -*- coding: utf-8 -*-
"""é’¢ç­‹å‘è´§ç›‘æ§ç³»ç»Ÿï¼ˆä¸­é“æ€»éƒ¨è§†å›¾ç‰ˆï¼‰- å…¨ä¸­æ–‡æ·±è“åœ°å›¾ä¿®å¤ç‰ˆ"""
import os
import re
import time
from datetime import datetime, timedelta
import pandas as pd
import streamlit as st
import requests
import hashlib
import json
import pydeck as pdk
import random

# ==================== ç³»ç»Ÿé…ç½® ====================
class AppConfig:
    DATA_PATHS = [
        os.path.join(os.path.dirname(__file__), "å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsm"),
        os.path.join(os.path.dirname(__file__), "å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsx"),
        r"F:\1.ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸-å››å·ç‰©ä¾›ä¸­å¿ƒ\é’¢æ-ç»“ç®—\é’¢ç­‹å‘è´§è®¡åˆ’-å‘ä¸å°åˆš\å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsx",
        r"D:\PyCharm\PycharmProjects\project\å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsx"
    ]

    LOGISTICS_SHEET_NAME = "ç‰©æµæ˜ç»†"
    LOGISTICS_COLUMNS = [
        "é’¢å‚", "ç‰©èµ„åç§°", "è§„æ ¼å‹å·", "å•ä½", "æ•°é‡",
        "äº¤è´§æ—¶é—´", "å¸è´§åœ°å€", "è”ç³»äºº", "è”ç³»æ–¹å¼", "é¡¹ç›®éƒ¨",
        "åˆ°è´§çŠ¶æ€", "å¤‡æ³¨"
    ]

    DATE_FORMAT = "%Y-%m-%d"
    BACKUP_COL_MAPPING = {
        'æ ‡æ®µåç§°': ['é¡¹ç›®æ ‡æ®µ', 'å·¥ç¨‹åç§°', 'æ ‡æ®µ'],
        'ç‰©èµ„åç§°': ['ææ–™åç§°', 'å“å', 'åç§°'],
        'éœ€æ±‚é‡': ['éœ€æ±‚å¨ä½', 'è®¡åˆ’é‡', 'æ•°é‡'],
        'ä¸‹å•æ—¶é—´': ['åˆ›å»ºæ—¶é—´', 'æ—¥æœŸ', 'å½•å…¥æ—¶é—´']
    }
    WEBHOOK_URL = "https://open.feishu.cn/open-apis/bot/v2/hook/dcf16af3-78d2-433f-9c3d-b4cd108c7b60"
    
    LOGISTICS_STATUS_FILE = "logistics_status.csv"
    STATUS_OPTIONS = ["å…¬å¸ç»Ÿç­¹ä¸­", "é’¢å‚å·²æ¥å•", "è¿è¾“è£…è´§ä¸­", "å·²åˆ°è´§", "æœªåˆ°è´§"]
    PROJECT_COLUMN = "é¡¹ç›®éƒ¨åç§°"

    PROJECT_MAPPING = {
        "ztwm": "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸",
        "sdtjdzzyykjy": "å•†æŠ•å»ºå·¥è¾¾å·ä¸­åŒ»è¯ç§‘æŠ€å›­",
        "hxjyxcjy": "åè¥¿ç®€é˜³è¥¿åŸå˜‰è‹‘",
        "hxjcn": "åè¥¿é…’åŸå—",
        "hxmhkckjstg": "åè¥¿èŒæµ·-ç§‘åˆ›å†œä¸šç”Ÿæ€è°·",
        "hxxlxx": "åè¥¿å…´éš†å­¦æ ¡",
        "hxyhkckjstg": "åè¥¿é¢æµ·-ç§‘åˆ›å†œä¸šç”Ÿæ€è°·",
    }

    # ã€åœ°å€åº“ 1ã€‘é¡¹ç›®åæ ‡ (åŸå¸‚çº§åˆ«æ¨¡ç³ŠåŒ¹é…)
    CITY_COORDINATES = {
        "å®œå®¾": [104.6432, 28.7518],
        "å—æºª": [104.9811, 28.8398],
        "æˆéƒ½": [104.0665, 30.5723],
        "é¾™æ³‰": [104.2746, 30.5566],
        "ç®€é˜³": [104.5486, 30.3904],
        "å¤©åºœ": [104.0757, 30.4045],
        "åŒæµ": [103.9237, 30.5744],
        "é”¦æ±Ÿ": [104.0809, 30.5951],
        "è¾¾å·": [107.5022, 31.2094],
        "ä¹å±±": [103.7656, 29.5520],
        "å°„æ´ª": [105.3892, 30.8712],
        "æ³¸å·": [105.4422, 28.8715],
        "é…’åŸ": [105.4422, 28.8715],
        "è¥¿æ¸": [108.3000, 31.2000],
        "æˆè¾¾ä¸‡": [106.5000, 31.5000],
        "é›…å®‰": [103.0000, 29.9800],
        "çœ‰å±±": [103.8000, 30.0700],
        "ç»µé˜³": [104.7000, 31.4600],
        "è‡ªè´¡": [104.7700, 29.3500],
    }
    
    # ã€åœ°å€åº“ 2ã€‘é’¢å‚åæ ‡ (ç”¨äºç»˜åˆ¶é£çº¿èµ·ç‚¹)
    FACTORY_COORDINATES = {
        "è¾¾é’¢": [107.50, 31.21],   # è¾¾å·
        "å¨é’¢": [104.70, 29.50],   # å†…æ±Ÿå¨è¿œ
        "å·ç¦": [104.30, 30.80],   # ä»€é‚¡/å¾·é˜³é™„è¿‘
        "é¾™é’¢": [110.44, 35.47],   # é™•è¥¿éŸ©åŸ
        "é™•é’¢": [108.93, 34.34],   # è¥¿å®‰
        "é‡é’¢": [106.55, 29.57],   # é‡åº†
        "é•¿å³°": [104.06, 30.57],   # æˆéƒ½(å‡è®¾)
        "æ”€é’¢": [101.71, 26.58],   # æ”€æèŠ±
        "æ˜†é’¢": [102.71, 25.04],   # æ˜†æ˜
        "å¾·èƒœ": [103.76, 29.55],   # ä¹å±±
        "æˆå®": [104.06, 30.60],   # æˆéƒ½
        "é™•è¥¿": [108.93, 34.34],
        "é‡åº†": [106.55, 29.57],
    }
    
    DEFAULT_CENTER = [104.0665, 30.5723]

    CARD_STYLES = {
        "hover_shadow": "0 8px 16px rgba(0,0,0,0.2)",
        "glass_effect": """
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(12px);
            -webkit-backdrop-filter: blur(12px);
            border-radius: 10px;
            border: 1px solid rgba(255, 255, 255, 0.18);
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
        """
    }


# ==================== è¾…åŠ©å‡½æ•° ====================
def find_data_file():
    for path in AppConfig.DATA_PATHS:
        if os.path.exists(path):
            return path
    current_dir = os.path.dirname(__file__)
    if current_dir:
        excel_files = [f for f in os.listdir(current_dir) if f.endswith(('.xlsx', '.xls', '.xlsm'))]
        if excel_files:
            return os.path.join(current_dir, excel_files[0])
    st.error("âŒ æœªæ‰¾åˆ°ä»»ä½•Excelæ•°æ®æ–‡ä»¶")
    return None

def get_coordinates(name, db, default_jitter=True):
    """é€šç”¨åæ ‡è·å–å‡½æ•°"""
    if not isinstance(name, str):
        return [104.0 + random.uniform(-0.1, 0.1), 30.5 + random.uniform(-0.1, 0.1)]
    
    base_coord = None
    # 1. ç²¾ç¡®/æ¨¡ç³ŠåŒ¹é…
    for key, coord in db.items():
        if key in name:
            base_coord = coord
            break
            
    # 2. é»˜è®¤å€¼
    if base_coord is None:
        return None 
            
    # 3. éšæœºæŠ–åŠ¨ (é˜²æ­¢ç‚¹é‡åˆ)
    if default_jitter:
        return [
            base_coord[0] + random.uniform(-0.03, 0.03),
            base_coord[1] + random.uniform(-0.03, 0.03)
        ]
    return base_coord

def apply_card_styles():
    st.markdown(f"""
    <style>
        .remark-card {{
            background: rgba(245, 245, 247, 0.9);
            border-radius: 10px;
            padding: 1rem;
            margin: 1.5rem 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            border-left: 4px solid;
        }}
        .plan-remark {{ border-color: #2196F3; }}
        .logistics-remark {{ border-color: #4CAF50; }}
        .remark-content {{
            font-size: 1rem;
            color: #666;
            text-align: center;
            padding: 1rem;
        }}
        .metric-container {{ 
            display: grid; 
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); 
            gap: 1rem; 
            margin: 1rem 0; 
        }}
        .metric-card {{
            {AppConfig.CARD_STYLES['glass_effect']}
            transition: all 0.3s ease;
            padding: 1.5rem;
        }}
        .metric-card:hover {{
            transform: translateY(-5px);
            box-shadow: 0 8px 16px rgba(0,0,0,0.2);
        }}
        .card-value {{
            font-size: 2rem;
            font-weight: 700;
            background: linear-gradient(45deg, #2c3e50, #3498db);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin: 0.5rem 0;
        }}
        .batch-update-card {{
            background: rgba(255, 255, 255, 0.95);
            border-radius: 10px;
            padding: 1.5rem;
            margin: 1.5rem 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            border-left: 4px solid #3498db;
        }}
        .batch-update-title {{
            font-size: 1.2rem;
            font-weight: bold;
            margin-bottom: 1rem;
            color: #2c3e50;
        }}
        .map-container-title {{
            color: #00f2ea;
            font-family: 'Courier New', monospace;
            text-shadow: 0 0 10px #00f2ea;
            margin-bottom: 10px;
        }}
    </style>
    """, unsafe_allow_html=True)


def generate_record_id(row):
    key_fields = [
        str(row["é’¢å‚"]),
        str(row["ç‰©èµ„åç§°"]),
        str(row["è§„æ ¼å‹å·"]),
        str(row["äº¤è´§æ—¶é—´"]),
        str(row["é¡¹ç›®éƒ¨"])
    ]
    return hashlib.md5("|".join(key_fields).encode('utf-8')).hexdigest()


def send_feishu_notification(material_info):
    message = {
        "msg_type": "interactive",
        "card": {
            "config": {"wide_screen_mode": True},
            "elements": [{
                "tag": "div",
                "text": {
                    "content": f"**ç‰©èµ„åç§°**: {material_info['ç‰©èµ„åç§°']}\n"
                               f"**è§„æ ¼å‹å·**: {material_info['è§„æ ¼å‹å·']}\n"
                               f"**æ•°é‡**: {material_info['æ•°é‡']}\n"
                               f"**äº¤è´§æ—¶é—´**: {material_info['äº¤è´§æ—¶é—´']}\n"
                               f"**é¡¹ç›®éƒ¨**: {material_info['é¡¹ç›®éƒ¨']}",
                    "tag": "lark_md"
                }
            }, {
                "tag": "hr"
            }, {
                "tag": "note",
                "elements": [{
                    "content": "âš ï¸ è¯¥ç‰©èµ„çŠ¶æ€å·²æ›´æ–°ä¸ºã€æœªåˆ°è´§ã€‘ï¼Œè¯·åŠæ—¶è·Ÿè¿›",
                    "tag": "plain_text"
                }]
            }],
            "header": {
                "template": "red",
                "title": {
                    "content": "ã€ç‰©æµçŠ¶æ€æ›´æ–°é€šçŸ¥ã€‘",
                    "tag": "plain_text"
                }
            }
        }
    }
    try:
        requests.post(AppConfig.WEBHOOK_URL, data=json.dumps(message), headers={'Content-Type': 'application/json'})
        return True
    except Exception:
        return False


# ==================== æ•°æ®åŠ è½½ ====================
@st.cache_data(ttl=3600)
def load_data():
    def safe_convert_to_numeric(series, default=0):
        str_series = series.astype(str)
        cleaned = str_series.str.replace(r'[^\d.-]', '', regex=True)
        cleaned = cleaned.replace({'': '0', 'nan': '0', 'None': '0'})
        return pd.to_numeric(cleaned, errors='coerce').fillna(default)

    data_path = find_data_file()
    if not data_path:
        st.error("âŒ æœªæ‰¾åˆ°å‘è´§è®¡åˆ’æ•°æ®æ–‡ä»¶")
        return pd.DataFrame()

    try:
        df = pd.read_excel(data_path, engine='openpyxl')
        for std_col, alt_cols in AppConfig.BACKUP_COL_MAPPING.items():
            for alt_col in alt_cols:
                if alt_col in df.columns and std_col not in df.columns:
                    df.rename(columns={alt_col: std_col}, inplace=True)
                    break
        
        df["ç‰©èµ„åç§°"] = df["ç‰©èµ„åç§°"].astype(str).str.strip().replace({"": "æœªæŒ‡å®š", "nan": "æœªæŒ‡å®š"})
        df[AppConfig.PROJECT_COLUMN] = df.iloc[:, 17].astype(str).str.strip().replace({"": "æœªæŒ‡å®š", "nan": "æœªæŒ‡å®š"})
        df["ä¸‹å•æ—¶é—´"] = pd.to_datetime(df["ä¸‹å•æ—¶é—´"], errors='coerce')
        df["éœ€æ±‚é‡"] = safe_convert_to_numeric(df["éœ€æ±‚é‡"]).astype(int)
        df["å·²å‘é‡"] = safe_convert_to_numeric(df.get("å·²å‘é‡", 0)).astype(int)
        df["å‰©ä½™é‡"] = (df["éœ€æ±‚é‡"] - df["å·²å‘é‡"]).clip(lower=0).astype(int)
        
        try:
            df["è¶…æœŸå¤©æ•°"] = safe_convert_to_numeric(df.iloc[:, 15]).astype(int)
        except:
            df["è¶…æœŸå¤©æ•°"] = 0
            
        return df
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return pd.DataFrame()


@st.cache_data(ttl=3600)
def load_logistics_data():
    data_path = find_data_file()
    if not data_path:
        return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])

    try:
        df = pd.read_excel(data_path, sheet_name=AppConfig.LOGISTICS_SHEET_NAME, engine='openpyxl')
        if df.shape[1] > 6:
            df["å¸è´§åœ°å€"] = df.iloc[:, 6].astype(str).replace({"nan": "", "None": ""})
        else:
            df["å¸è´§åœ°å€"] = ""

        for col in AppConfig.LOGISTICS_COLUMNS:
            if col not in df.columns:
                df[col] = "" if col != "æ•°é‡" else 0

        for col in ["ç‰©èµ„åç§°", "é’¢å‚", "é¡¹ç›®éƒ¨"]:
            df[col] = df[col].astype(str).str.strip().replace({"nan": "", "None": ""})
        
        df = df[df["é¡¹ç›®éƒ¨"] != ""]
        df["æ•°é‡"] = pd.to_numeric(df["æ•°é‡"], errors='coerce').fillna(0)
        df["äº¤è´§æ—¶é—´"] = pd.to_datetime(df["äº¤è´§æ—¶é—´"], errors="coerce")
        df["record_id"] = df.apply(generate_record_id, axis=1)

        return df[AppConfig.LOGISTICS_COLUMNS + ["record_id"]]

    except Exception:
        return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])


# ==================== çŠ¶æ€ç®¡ç† ====================
def load_logistics_status():
    if os.path.exists(AppConfig.LOGISTICS_STATUS_FILE):
        try:
            return pd.read_csv(AppConfig.LOGISTICS_STATUS_FILE)
        except:
            pass
    return pd.DataFrame(columns=["record_id", "åˆ°è´§çŠ¶æ€", "update_time"])

def save_logistics_status(status_df):
    try:
        status_df.to_csv(AppConfig.LOGISTICS_STATUS_FILE, index=False, encoding='utf-8-sig')
        return True
    except:
        return False

def merge_logistics_with_status(logistics_df):
    if logistics_df.empty: return logistics_df
    status_df = load_logistics_status()
    
    if "åˆ°è´§çŠ¶æ€" not in logistics_df.columns:
        logistics_df["åˆ°è´§çŠ¶æ€"] = "é’¢å‚å·²æ¥å•"
        
    current_date = datetime.now().date()
    three_days_ago = current_date - timedelta(days=3)
    
    if not status_df.empty:
        status_df = status_df[["record_id", "åˆ°è´§çŠ¶æ€"]]
        logistics_df = pd.merge(logistics_df, status_df, on="record_id", how="left", suffixes=("", "_db"))
        logistics_df["åˆ°è´§çŠ¶æ€"] = logistics_df["åˆ°è´§çŠ¶æ€_db"].combine_first(logistics_df["åˆ°è´§çŠ¶æ€"])
        logistics_df = logistics_df.drop(columns=["åˆ°è´§çŠ¶æ€_db"], errors='ignore')

    mask_auto = (logistics_df["åˆ°è´§çŠ¶æ€"].isna()) | (logistics_df["åˆ°è´§çŠ¶æ€"] == "é’¢å‚å·²æ¥å•")
    mask_time = logistics_df["äº¤è´§æ—¶é—´"].apply(lambda x: pd.notna(x) and x.date() < three_days_ago)
    logistics_df.loc[mask_auto & mask_time, "åˆ°è´§çŠ¶æ€"] = "å·²åˆ°è´§"
    logistics_df["åˆ°è´§çŠ¶æ€"] = logistics_df["åˆ°è´§çŠ¶æ€"].fillna("é’¢å‚å·²æ¥å•")
    
    return logistics_df

def update_logistics_status(record_id, new_status, original_row=None):
    status_df = load_logistics_status()
    if record_id in status_df["record_id"].values:
        status_df.loc[status_df["record_id"] == record_id, "åˆ°è´§çŠ¶æ€"] = new_status
        status_df.loc[status_df["record_id"] == record_id, "update_time"] = datetime.now().strftime(AppConfig.DATE_FORMAT)
    else:
        new_rec = pd.DataFrame([{"record_id": record_id, "åˆ°è´§çŠ¶æ€": new_status, "update_time": datetime.now().strftime(AppConfig.DATE_FORMAT)}])
        status_df = pd.concat([status_df, new_rec], ignore_index=True)
    
    if save_logistics_status(status_df):
        if new_status == "æœªåˆ°è´§" and original_row is not None:
            material_info = {
                "ç‰©èµ„åç§°": original_row["ç‰©èµ„åç§°"],
                "è§„æ ¼å‹å·": original_row["è§„æ ¼å‹å·"],
                "æ•°é‡": original_row["æ•°é‡"],
                "äº¤è´§æ—¶é—´": original_row["äº¤è´§æ—¶é—´"].strftime("%Y-%m-%d %H:%M") if pd.notna(original_row["äº¤è´§æ—¶é—´"]) else "æœªçŸ¥",
                "é¡¹ç›®éƒ¨": original_row["é¡¹ç›®éƒ¨"]
            }
            send_feishu_notification(material_info)
        return True
    return False

def batch_update_logistics_status(record_ids, new_status, original_rows=None):
    status_df = load_logistics_status()
    now = datetime.now().strftime(AppConfig.DATE_FORMAT)
    cnt = 0
    
    new_records = []
    existing_ids = set(status_df["record_id"].values)
    
    for rid in record_ids:
        if rid in existing_ids:
            status_df.loc[status_df["record_id"] == rid, "åˆ°è´§çŠ¶æ€"] = new_status
            status_df.loc[status_df["record_id"] == rid, "update_time"] = now
        else:
            new_records.append({"record_id": rid, "åˆ°è´§çŠ¶æ€": new_status, "update_time": now})
        cnt += 1
        
    if new_records:
        status_df = pd.concat([status_df, pd.DataFrame(new_records)], ignore_index=True)
        
    save_logistics_status(status_df)
    return cnt, 0


# ==================== ã€å…¨ä¸­æ–‡ã€‘3D é£çº¿é©¾é©¶èˆ± ====================
def show_cockpit_tab():
    st.markdown('<h3 class="map-container-title">ğŸ›¸ G.L.M.S - 3D é£çº¿æˆ˜æœ¯åœ°å›¾</h3>', unsafe_allow_html=True)
    
    logistics_df = load_logistics_data()
    if logistics_df.empty:
        st.info("æš‚æ— æ•°æ®")
        return

    # æ•°æ®å¤„ç†ï¼šåŒ¹é…åæ ‡
    grouped = logistics_df.groupby(["é¡¹ç›®éƒ¨", "é’¢å‚"])["æ•°é‡"].sum().reset_index()
    grouped["target_coord"] = grouped["é¡¹ç›®éƒ¨"].apply(lambda x: get_coordinates(x, AppConfig.CITY_COORDINATES, True))
    grouped["source_coord"] = grouped["é’¢å‚"].apply(lambda x: get_coordinates(x, AppConfig.FACTORY_COORDINATES, True))
    
    valid_data = grouped.dropna(subset=["target_coord", "source_coord"]).copy()
    if valid_data.empty:
        st.warning("âš ï¸ æ— æ³•åŒ¹é…åæ ‡ï¼Œè¯·æ£€æŸ¥é¡¹ç›®/é’¢å‚åç§°æ˜¯å¦åŒ…å«å…³é”®è¯ (å¦‚: å®œå®¾, æˆéƒ½)")
        return
        
    valid_data["t_lon"] = valid_data["target_coord"].apply(lambda x: x[0])
    valid_data["t_lat"] = valid_data["target_coord"].apply(lambda x: x[1])
    valid_data["s_lon"] = valid_data["source_coord"].apply(lambda x: x[0])
    valid_data["s_lat"] = valid_data["source_coord"].apply(lambda x: x[1])
    
    # é¢œè‰²ç­–ç•¥
    def get_color(val):
        if val > 100: return [255, 69, 0, 180] # Red-Orange
        if val > 50: return [255, 215, 0, 160] # Gold
        return [0, 255, 255, 140] # Cyan

    valid_data["color"] = valid_data["æ•°é‡"].apply(get_color)

    # äº¤äº’æ§åˆ¶
    col_sel, col_info = st.columns([1, 2])
    with col_sel:
        selected_proj = st.selectbox("ğŸ”­ èšç„¦é˜µåœ°", ["å…¨éƒ¨æ˜¾ç¤º"] + sorted(list(valid_data["é¡¹ç›®éƒ¨"].unique())))

    view_state = pdk.ViewState(latitude=30.8, longitude=105.0, zoom=6.5, pitch=60)
    if selected_proj != "å…¨éƒ¨æ˜¾ç¤º":
        target = valid_data[valid_data["é¡¹ç›®éƒ¨"] == selected_proj].iloc[0]
        view_state = pdk.ViewState(latitude=target["t_lat"], longitude=target["t_lon"], zoom=9, pitch=60, bearing=30)

    # ================= 3D å›¾å±‚æ„å»º =================
    layers = []
    
    # 0. åº•å›¾å±‚ï¼šå¼ºåˆ¶ä½¿ç”¨ã€æ™ºå›¾-æ·±è“å¤œè‰²ã€‘ä¸­æ–‡ç“¦ç‰‡
    base_map_layer = pdk.Layer(
        "TileLayer",
        data=None,
        # GeoQ æ™ºå›¾ - æ·±è“å¤œè‰² (å…¨ä¸­æ–‡)
        get_tile_data="https://map.geoq.cn/ArcGIS/rest/services/ChinaOnlineStreetPurplishBlue/MapServer/tile/{z}/{y}/{x}",
        min_zoom=0,
        max_zoom=16,
        tileSize=256,
        pickable=False,
    )
    layers.append(base_map_layer)

    # 1. é£çº¿å±‚
    arc_layer = pdk.Layer(
        "ArcLayer",
        data=valid_data,
        get_source_position=["s_lon", "s_lat"],
        get_target_position=["t_lon", "t_lat"],
        get_source_color=[0, 255, 255, 80],
        get_target_color="color",
        get_width=3,
        get_tilt=15,
        pickable=True,
    )
    layers.append(arc_layer)

    # 2. æŸ±çŠ¶å›¾å±‚
    proj_agg = valid_data.groupby(["é¡¹ç›®éƒ¨", "t_lon", "t_lat"])["æ•°é‡"].sum().reset_index()
    proj_agg["color"] = proj_agg["æ•°é‡"].apply(get_color)
    
    column_layer = pdk.Layer(
        "ColumnLayer",
        data=proj_agg,
        get_position=["t_lon", "t_lat"],
        get_elevation="æ•°é‡",
        elevation_scale=100,
        radius=1000,
        get_fill_color="color",
        pickable=True,
        extruded=True,
        auto_highlight=True,
    )
    layers.append(column_layer)

    # 3. æ–‡æœ¬å±‚ (ä¸­æ–‡æ ‡æ³¨ï¼Œå¼¥è¡¥åº•å›¾å­—ä½“è¿‡å°çš„é—®é¢˜)
    text_layer = pdk.Layer(
        "TextLayer",
        data=proj_agg,
        get_position=["t_lon", "t_lat"],
        get_text="é¡¹ç›®éƒ¨",
        get_color=[255, 255, 255],
        get_size=13,
        get_alignment_baseline="'bottom'",
        get_text_anchor="'middle'",
        get_pixel_offset=[0, -15],
    )
    layers.append(text_layer)

    tooltip = {
        "html": "<b>{é¡¹ç›®éƒ¨}</b><br/>ä» {é’¢å‚} å‘è´§<br/>ğŸ“¦ æ•°é‡: {æ•°é‡} å¨",
        "style": {"backgroundColor": "#111", "color": "#fff", "border": "1px solid #00f2ea"}
    }
    
    st.pydeck_chart(pdk.Deck(
        map_provider=None, 
        initial_view_state=view_state,
        layers=layers,
        tooltip=tooltip,
        parameters={"blendFunc": [770, 771]} 
    ))

    if selected_proj != "å…¨éƒ¨æ˜¾ç¤º":
        st.info(f"âœ… å½“å‰èšç„¦ï¼š{selected_proj}")
        dt = logistics_df[logistics_df["é¡¹ç›®éƒ¨"] == selected_proj]
        st.dataframe(dt[["äº¤è´§æ—¶é—´", "ç‰©èµ„åç§°", "é’¢å‚", "æ•°é‡", "åˆ°è´§çŠ¶æ€"]].head(10), use_container_width=True)


# ==================== ç‰©æµæ˜ç»† Tab (ä¿®å¤ç‰ˆ) ====================
def auto_process_logistics_changes(edited_df, original_filtered_df, project):
    if f'logistics_editor_{project}' not in st.session_state: return
    changed = st.session_state[f'logistics_editor_{project}'].get('edited_rows', {})
    if not changed: return

    pkey = f"processed_changes_{project}"
    if pkey not in st.session_state: st.session_state[pkey] = set()

    count = 0
    for idx_str, changes in changed.items():
        chash = f"{idx_str}_{changes.get('åˆ°è´§çŠ¶æ€', '')}"
        if chash not in st.session_state[pkey]:
            st.session_state[pkey].add(chash)
            try:
                idx = int(idx_str)
                if idx < len(original_filtered_df):
                    rec_id = original_filtered_df.iloc[idx]["record_id"]
                    orig = original_filtered_df.iloc[idx]
                    nst = changes.get("åˆ°è´§çŠ¶æ€", orig["åˆ°è´§çŠ¶æ€"])
                    if nst != orig["åˆ°è´§çŠ¶æ€"]:
                        if update_logistics_status(rec_id, nst, orig):
                            count += 1
                            st.toast(f"âœ… {orig['ç‰©èµ„åç§°']} çŠ¶æ€æ›´æ–°", icon="ok")
            except: pass
    
    if count > 0:
        time.sleep(1)
        st.rerun()

def show_logistics_tab(project):
    yesterday = datetime.now().date() - timedelta(days=1)
    col1, col2 = st.columns(2)
    with col1: start = st.date_input("å¼€å§‹æ—¥æœŸ", yesterday, key="log_s")
    with col2: end = st.date_input("ç»“æŸæ—¥æœŸ", yesterday, key="log_e")

    with st.spinner("åŠ è½½ç‰©æµä¿¡æ¯..."):
        df = load_logistics_data()
        if project != "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸":
            df = df[df["é¡¹ç›®éƒ¨"] == project]

        if not df.empty:
            df = merge_logistics_with_status(df)
            mask = (df["äº¤è´§æ—¶é—´"] >= pd.to_datetime(start)) & (df["äº¤è´§æ—¶é—´"] < pd.to_datetime(end) + timedelta(days=1))
            filtered = df[mask].copy()

            # Metrics
            st.markdown('<div class="metric-container">', unsafe_allow_html=True)
            total = len(filtered)
            arrived = filtered['åˆ°è´§çŠ¶æ€'].eq('å·²åˆ°è´§').sum()
            overdue = filtered['åˆ°è´§çŠ¶æ€'].eq('æœªåˆ°è´§').sum()
            progress = total - arrived - overdue
            cols = st.columns(4)
            metrics = [("ğŸ“¦ æ€»å•æ•°", total), ("âœ… å·²åˆ°è´§", arrived), ("ğŸ”„ è¿›è¡Œä¸­", progress), ("âš ï¸ æœªåˆ°è´§", overdue)]
            for i, (l, v) in enumerate(metrics):
                with cols[i]:
                    st.markdown(f'<div class="metric-card"><div style="font-size:1.2rem">{l}</div><div class="card-value">{v}</div></div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

            # Batch Update
            st.markdown("""<div class="batch-update-card"><div class="batch-update-title">ğŸ“¦ æ‰¹é‡æ›´æ–°åˆ°è´§çŠ¶æ€</div></div>""", unsafe_allow_html=True)
            b1, b2, b3 = st.columns([2, 1, 1])
            with b1:
                rmap = {f"{r['ç‰©èµ„åç§°']}-{r['é’¢å‚']}-{r['æ•°é‡']}t": r['record_id'] for _, r in filtered.iterrows()}
                sels = st.multiselect("é€‰æ‹©è®°å½•", list(rmap.keys()))
            with b2:
                nst = st.selectbox("çŠ¶æ€", AppConfig.STATUS_OPTIONS)
            with b3:
                st.write(""); st.write("")
                if st.button("ğŸš€ æ›´æ–°", type="primary") and sels:
                    ids = [rmap[k] for k in sels]
                    rows = [filtered[filtered['record_id'] == i].iloc[0] for i in ids]
                    s, e = batch_update_logistics_status(ids, nst, rows)
                    if s > 0: st.success(f"å·²æ›´æ–° {s} æ¡"); st.rerun()

            # Data Editor
            disp_cols = [c for c in filtered.columns if c not in ["record_id", "æ”¶è´§åœ°å€"]]
            disp_df = filtered[disp_cols].reset_index(drop=True)
            st.markdown("**ç‰©æµæ˜ç»†è¡¨** (ä¿®æ”¹è‡ªåŠ¨ä¿å­˜)")
            edited = st.data_editor(
                disp_df,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "åˆ°è´§çŠ¶æ€": st.column_config.SelectboxColumn("åˆ°è´§çŠ¶æ€", options=AppConfig.STATUS_OPTIONS, required=True),
                    "äº¤è´§æ—¶é—´": st.column_config.DatetimeColumn("äº¤è´§æ—¶é—´", format="YYYY-MM-DD HH:mm"),
                },
                key=f"logistics_editor_{project}"
            )
            auto_process_logistics_changes(edited, filtered, project)
        else:
            st.info("ğŸ“­ å½“å‰æ— æ•°æ®")


# ==================== å…¶ä»– Tab ç»„ä»¶ ====================
def show_plan_tab(df, project):
    col1, col2 = st.columns(2)
    with col1: start = st.date_input("å¼€å§‹", datetime.now(), key="ps")
    with col2: end = st.date_input("ç»“æŸ", datetime.now(), key="pe")
    
    filtered = df if project == "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸" else df[df[AppConfig.PROJECT_COLUMN] == project]
    mask = (filtered["ä¸‹å•æ—¶é—´"].dt.date >= start) & (filtered["ä¸‹å•æ—¶é—´"].dt.date <= end)
    res = filtered[mask]
    
    if not res.empty:
        total = int(res["éœ€æ±‚é‡"].sum())
        shipped = int(res["å·²å‘é‡"].sum())
        cols = st.columns(3)
        cols[0].metric("æ€»éœ€æ±‚", f"{total} å¨")
        cols[1].metric("å·²å‘è´§", f"{shipped} å¨")
        cols[2].metric("è¿›åº¦", f"{shipped/total*100:.1f}%" if total>0 else "0%")
        
        target_cols = {
            "æ ‡æ®µåç§°": "å·¥ç¨‹æ ‡æ®µ", "ç‰©èµ„åç§°": "ææ–™åç§°", "è§„æ ¼å‹å·": "è§„æ ¼å‹å·",
            "éœ€æ±‚é‡": "éœ€æ±‚(å¨)", "å·²å‘é‡": "å·²å‘(å¨)", "å‰©ä½™é‡": "å¾…å‘(å¨)",
            "è¶…æœŸå¤©æ•°": "è¶…æœŸå¤©æ•°", "ä¸‹å•æ—¶é—´": "ä¸‹å•", "è®¡åˆ’è¿›åœºæ—¶é—´": "è®¡åˆ’è¿›åœº"
        }
        available = {k: v for k, v in target_cols.items() if k in res.columns}
        disp = res[list(available.keys())].rename(columns=available)
        st.dataframe(disp, use_container_width=True, hide_index=True)
    else:
        st.info("æ— æ•°æ®")

def show_statistics_tab(df):
    st.subheader("ğŸ“Š æ•°æ®ç»Ÿè®¡")
    log_df = load_logistics_data()
    if log_df.empty: return
    grp = log_df.groupby(['é¡¹ç›®éƒ¨', 'é’¢å‚'])['æ•°é‡'].sum().reset_index()
    st.dataframe(grp, use_container_width=True)

# ==================== ä¸»æ§é€»è¾‘ ====================
def show_data_panel(df, project):
    st.title(f"{project} - å‘è´§æ•°æ®")
    
    c1, c2 = st.columns([1, 6])
    with c1: 
        if st.button("ğŸ”„ åˆ·æ–°"): st.cache_data.clear(); st.rerun()
    with c2:
        if st.button("ğŸ  é¦–é¡µ"): st.session_state.project_selected = False; st.rerun()

    if project == "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸":
        tabs = st.tabs(["ğŸš€ 3Dé£çº¿é©¾é©¶èˆ±", "ğŸ“‹ å‘è´§è®¡åˆ’", "ğŸš› ç‰©æµæ˜ç»†", "ğŸ“Š æ•°æ®ç»Ÿè®¡"])
        with tabs[0]: show_cockpit_tab()
        with tabs[1]: show_plan_tab(df, project)
        with tabs[2]: show_logistics_tab(project)
        with tabs[3]: show_statistics_tab(df)
    else:
        tabs = st.tabs(["ğŸ“‹ å‘è´§è®¡åˆ’", "ğŸš› ç‰©æµæ˜ç»†"])
        with tabs[0]: show_plan_tab(df, project)
        with tabs[1]: show_logistics_tab(project)

def show_project_selection(df):
    st.markdown("<h1 style='text-align: center;'>é’¢ç­‹å‘è´§ç›‘æ§ç³»ç»Ÿ</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: gray;'>ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸</p>", unsafe_allow_html=True)
    
    log_df = load_logistics_data()
    projs = sorted([p for p in log_df["é¡¹ç›®éƒ¨"].unique() if p]) if not log_df.empty else []
    
    sel = st.selectbox("é€‰æ‹©é¡¹ç›®éƒ¨", ["ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸"] + projs)
    if st.button("è¿›å…¥ç³»ç»Ÿ", type="primary", use_container_width=True):
        if sel == "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸":
            st.session_state.temp = sel; st.session_state.pwd = True
        else:
            st.session_state.project_selected = True; st.session_state.selected_project = sel; st.rerun()
            
    if st.session_state.get('pwd', False):
        if st.text_input("å¯†ç ", type="password") == "123456":
            st.session_state.project_selected = True; st.session_state.selected_project = st.session_state.temp; st.rerun()

def main():
    st.set_page_config(layout="wide", page_title="å‘è´§ç›‘æ§", page_icon="ğŸ—ï¸")
    apply_card_styles()
    
    if 'project_selected' not in st.session_state: st.session_state.project_selected = False
    
    qp = st.query_params
    if 'project' in qp:
        pkey = qp['project'] if not isinstance(qp['project'], list) else qp['project'][0]
        pname = AppConfig.PROJECT_MAPPING.get(pkey.lower(), "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸")
        st.session_state.project_selected = True
        st.session_state.selected_project = pname

    df = load_data()
    if not st.session_state.project_selected:
        show_project_selection(df)
    else:
        show_data_panel(df, st.session_state.selected_project)

if __name__ == "__main__":
    main()
