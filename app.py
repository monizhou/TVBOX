# -*- coding: utf-8 -*-
"""é’¢ç­‹å‘è´§ç›‘æ§ç³»ç»Ÿï¼ˆä¸­é“æ€»éƒ¨è§†å›¾ç‰ˆï¼‰- æˆ˜æœ¯é›·è¾¾åŠ¨ç”»ç‰ˆ"""
import os
import re
import time
from datetime import datetime, timedelta
import pandas as pd
import streamlit as st
import requests
import hashlib
import json
import plotly.express as px
import plotly.graph_objects as go

# ==================== ç³»ç»Ÿé…ç½® ====================
class AppConfig:
    DATA_PATHS = [
        os.path.join(os.path.dirname(__file__), "å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsm"),
        os.path.join(os.path.dirname(__file__), "å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsx"),
        r"F:\1.ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸-å››å·ç‰©ä¾›ä¸­å¿ƒ\é’¢æ-ç»“ç®—\é’¢ç­‹å‘è´§è®¡åˆ’-å‘ä¸å°åˆš\å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsx",
        r"D:\PyCharm\PycharmProjects\project\å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsx"
    ]

    LOGISTICS_SHEET_NAME = "ç‰©æµæ˜ç»†"
    
    # è°ƒæ•´åˆ—é¡ºåºï¼Œ"å¸è´§åœ°å€" æ”¾åœ¨ "è”ç³»äºº" å·¦è¾¹
    LOGISTICS_COLUMNS = [
        "é’¢å‚", "ç‰©èµ„åç§°", "è§„æ ¼å‹å·", "å•ä½", "æ•°é‡",
        "äº¤è´§æ—¶é—´", "å¸è´§åœ°å€", "è”ç³»äºº", "è”ç³»æ–¹å¼", "é¡¹ç›®éƒ¨",
        "åˆ°è´§çŠ¶æ€", "å¤‡æ³¨"
    ]

    DATE_FORMAT = "%Y-%m-%d"
    BACKUP_COL_MAPPING = {
        'æ ‡æ®µåç§°': ['é¡¹ç›®æ ‡æ®µ', 'å·¥ç¨‹åç§°', 'æ ‡æ®µ'],
        'ç‰©èµ„åç§°': ['ææ–™åç§°', 'å“å', 'åç§°'],
        'éœ€æ±‚é‡': ['éœ€æ±‚å¨ä½', 'è®¡åˆ’é‡', 'æ•°é‡'],
        'ä¸‹å•æ—¶é—´': ['åˆ›å»ºæ—¶é—´', 'æ—¥æœŸ', 'å½•å…¥æ—¶é—´']
    }
    WEBHOOK_URL = "https://open.feishu.cn/open-apis/bot/v2/hook/dcf16af3-78d2-433f-9c3d-b4cd108c7b60"
    
    LOGISTICS_STATUS_FILE = "logistics_status.csv"
    STATUS_OPTIONS = ["å…¬å¸ç»Ÿç­¹ä¸­", "é’¢å‚å·²æ¥å•", "è¿è¾“è£…è´§ä¸­", "å·²åˆ°è´§", "æœªåˆ°è´§"]
    PROJECT_COLUMN = "é¡¹ç›®éƒ¨åç§°"

    # é¡¹ç›®åç§°æ˜ å°„
    PROJECT_MAPPING = {
        "ztwm": "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸",
        "sdtjdzzyykjy": "å•†æŠ•å»ºå·¥è¾¾å·ä¸­åŒ»è¯ç§‘æŠ€å›­",
        "hxjyxcjy": "åè¥¿ç®€é˜³è¥¿åŸå˜‰è‹‘",
        "hxjcn": "åè¥¿é…’åŸå—",
        "hxmhkckjstg": "åè¥¿èŒæµ·-ç§‘åˆ›å†œä¸šç”Ÿæ€è°·",
        "hxxlxx": "åè¥¿å…´éš†å­¦æ ¡",
        "hxyhkckjstg": "åè¥¿é¢æµ·-ç§‘åˆ›å†œä¸šç”Ÿæ€è°·",
        "lssxdgjcjrhjdxm2": "ä¹å±±å¸‚æ ¡åœ°å…±å»ºäº§æ•™èåˆåŸºåœ°å»ºè®¾é¡¹ç›®äºŒæ ‡æ®µ",
        "lssxdgjcjrhjdxm1": "ä¹å±±å¸‚æ ¡åœ°å…±å»ºäº§æ•™èåˆåŸºåœ°å»ºè®¾é¡¹ç›®ä¸€æ ‡æ®µ",
        "scsjshtyh": "å››å·å•†å»ºå°„æ´ªåŸä¹¡ä¸€ä½“åŒ–é¡¹ç›®",
        "wyggdzswsgwslcylczx": "äº”å†¶é’¢æ„è¾¾å·å¸‚å…¬å…±å«ç”Ÿä¸´åºŠåŒ»ç–—ä¸­å¿ƒé¡¹ç›®",
        "wygglqdh": "äº”å†¶é’¢æ„é¾™æ³‰ä¸œæ´ªç‰‡åŒº(70äº©ã€85äº©)ä½å®…ã€å•†ä¸šåŠé…å¥—å·¥ç¨‹é¡¹ç›®",
        "wyggybnxgxyj": "äº”å†¶é’¢æ„-å®œå®¾å¸‚å—æºªåŒºé«˜å¿æœˆæ±Ÿé•‡å»ºè®¾é¡¹ç›®",
        "wyjscdgjtlgdsl": "äº”å†¶å»ºè®¾æˆéƒ½å›½é™…é“è·¯æ¸¯å¤šå¼è”é¡¹ç›®",
        "wyjscdydjzxczb": "äº”å†¶å»ºè®¾æˆéƒ½ç›é“è¡—ä¸­å­¦åˆä¸­éƒ¨æ”¹æ‰©å»ºå·¥ç¨‹",
        "wyjsjjqljb20": "äº”å†¶å»ºè®¾é”¦æ±ŸåŒºæ—å®¶åç‰‡åŒº20å·åœ°å—å•†ä¸šé¡¹ç›®",
        "wyjskgxcyxjd83": "äº”å†¶å»ºè®¾ç©ºæ¸¯å…´åŸæ€¡å¿ƒè¡—é“83äº©é¡¹ç›®",
        "wyjsklytzx2": "äº”å†¶å»ºè®¾æ‰©å»ºè‰ºä½“ä¸­å­¦äºŒæœŸå·¥ç¨‹",
        "wyjslqfrhy": "äº”å†¶å»ºè®¾é¾™æ³‰èŠ™è“‰èŠ±è¯­é¡¹ç›®",
        "wyjslqyyyypz": "äº”å†¶å»ºè®¾é¾™æ³‰é©¿ä¸€åŒ»é™¢é…å¥—å»ºè®¾å·¥ç¨‹",
        "wyjssdfzwyx": "äº”å†¶å»ºè®¾å¸ˆå¤§é™„ä¸­å¤–è¯­æ ¡æ–°å»ºæ•™å­¦æ¥¼å·¥ç¨‹",
        "whdqhjcdwqdgqdd": "æ­¦æ±‰ç”µæ°”åŒ–å±€æˆè¾¾ä¸‡é«˜é“å¼ºç”µé¡¹ç›®",
        "ybxgsjxcjgyy": "å®œå®¾å…´æ¸¯ä¸‰æ±Ÿæ–°åŒºé•¿æ±Ÿå·¥ä¸šå›­å»ºè®¾é¡¹ç›®",
        "ztkyybnx": "ä¸­é“ç§‘ç ”é™¢å®œå®¾æ³¥æºªé¡¹ç›®",
        "ztsjxtykyzf4": "ä¸­é“ä¸‰å±€é›†å›¢è¥¿æ¸é«˜é“åº·æ¸æ®µç«™æˆ¿å››æ ‡å·¥ç¨‹"
    }

    # æ¸…çˆ½çš„å¡ç‰‡æ ·å¼
    CARD_STYLES = {
        "glass_effect": """
            background: rgba(255, 255, 255, 0.9);
            border-radius: 10px;
            padding: 1.5rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            border: 1px solid #f0f2f6;
        """
    }


# ==================== è¾…åŠ©å‡½æ•° ====================
def find_data_file():
    for path in AppConfig.DATA_PATHS:
        if os.path.exists(path):
            return path
    current_dir = os.path.dirname(__file__)
    if current_dir:
        excel_files = [f for f in os.listdir(current_dir) if f.endswith(('.xlsx', '.xls', '.xlsm'))]
        if excel_files:
            return os.path.join(current_dir, excel_files[0])
    st.error("âŒ æœªæ‰¾åˆ°ä»»ä½•Excelæ•°æ®æ–‡ä»¶")
    return None


def apply_card_styles():
    st.markdown(f"""
    <style>
        .remark-card {{
            background: #f8f9fa;
            border-radius: 8px;
            padding: 1rem;
            margin: 1rem 0;
            border-left: 4px solid;
            color: #444;
        }}
        .plan-remark {{ border-color: #3498db; }}
        .logistics-remark {{ border-color: #2ecc71; }}
        .remark-content {{
            font-size: 1rem;
            text-align: center;
        }}
        .stTabs [data-baseweb="tab-list"] {{
            gap: 8px;
            padding: 8px 0;
            border-radius: 8px;
        }}
        .metric-container {{ 
            display: grid; 
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); 
            gap: 1rem; 
            margin: 1rem 0; 
        }}
        .metric-card {{
            {AppConfig.CARD_STYLES['glass_effect']}
            transition: transform 0.2s;
        }}
        .metric-card:hover {{
            transform: translateY(-3px);
            box-shadow: 0 6px 12px rgba(0,0,0,0.1);
        }}
        .card-value {{
            font-size: 2rem;
            font-weight: 700;
            color: #2c3e50;
            margin: 0.5rem 0;
        }}
        .card-unit {{
            font-size: 0.9rem;
            color: #666;
        }}
        div[data-testid="stDataEditor"] table td {{
            font-size: 13px !important;
        }}
        
        /* é¦–é¡µæ ·å¼ */
        .home-card {{
            background: white;
            padding: 2rem;
            border-radius: 12px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.05);
            text-align: center;
            transition: all 0.3s ease;
            border: 1px solid #eee;
            margin-bottom: 20px;
        }}
        .home-card:hover {{
            transform: translateY(-5px);
            box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        }}
        .home-card-title {{
            font-size: 1.4rem;
            font-weight: bold;
            margin: 1rem 0;
            color: #2c3e50;
        }}
        .home-card-icon {{
            font-size: 3rem;
            margin-bottom: 1rem;
        }}
    </style>
    """, unsafe_allow_html=True)


def generate_record_id(row):
    key_fields = [
        str(row["é’¢å‚"]),
        str(row["ç‰©èµ„åç§°"]),
        str(row["è§„æ ¼å‹å·"]),
        str(row["äº¤è´§æ—¶é—´"]),
        str(row["é¡¹ç›®éƒ¨"])
    ]
    return hashlib.md5("|".join(key_fields).encode('utf-8')).hexdigest()


def send_feishu_notification(material_info):
    message = {
        "msg_type": "interactive",
        "card": {
            "config": {"wide_screen_mode": True},
            "elements": [{
                "tag": "div",
                "text": {
                    "content": f"**ç‰©èµ„åç§°**: {material_info['ç‰©èµ„åç§°']}\n"
                               f"**è§„æ ¼å‹å·**: {material_info['è§„æ ¼å‹å·']}\n"
                               f"**æ•°é‡**: {material_info['æ•°é‡']}\n"
                               f"**äº¤è´§æ—¶é—´**: {material_info['äº¤è´§æ—¶é—´']}\n"
                               f"**é¡¹ç›®éƒ¨**: {material_info['é¡¹ç›®éƒ¨']}",
                    "tag": "lark_md"
                }
            }, {
                "tag": "hr"
            }, {
                "tag": "note",
                "elements": [{
                    "content": "âš ï¸ è¯¥ç‰©èµ„çŠ¶æ€å·²æ›´æ–°ä¸ºã€æœªåˆ°è´§ã€‘ï¼Œè¯·åŠæ—¶è·Ÿè¿›",
                    "tag": "plain_text"
                }]
            }],
            "header": {
                "template": "red",
                "title": {
                    "content": "ã€ç‰©æµçŠ¶æ€æ›´æ–°é€šçŸ¥ã€‘",
                    "tag": "plain_text"
                }
            }
        }
    }
    try:
        requests.post(AppConfig.WEBHOOK_URL, data=json.dumps(message), headers={'Content-Type': 'application/json'})
        return True
    except Exception:
        return False


# ==================== æ•°æ®åŠ è½½ ====================
@st.cache_data(ttl=3600)
def load_data():
    def safe_convert_to_numeric(series, default=0):
        str_series = series.astype(str)
        cleaned = str_series.str.replace(r'[^\d.-]', '', regex=True)
        cleaned = cleaned.replace({'': '0', 'nan': '0', 'None': '0'})
        return pd.to_numeric(cleaned, errors='coerce').fillna(default)

    data_path = find_data_file()
    if not data_path:
        return pd.DataFrame()

    try:
        with st.spinner("æ­£åœ¨åŠ è½½åŸºç¡€æ•°æ®..."):
            df = pd.read_excel(data_path, engine='openpyxl')

            for std_col, alt_cols in AppConfig.BACKUP_COL_MAPPING.items():
                for alt_col in alt_cols:
                    if alt_col in df.columns and std_col not in df.columns:
                        df.rename(columns={alt_col: std_col}, inplace=True)
                        break

            REQUIRED_COLS = ['æ ‡æ®µåç§°', 'ç‰©èµ„åç§°', 'ä¸‹å•æ—¶é—´', 'éœ€æ±‚é‡']
            missing_cols = [col for col in REQUIRED_COLS if col not in df.columns]
            if missing_cols:
                st.error(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                return pd.DataFrame()

            df["ç‰©èµ„åç§°"] = df["ç‰©èµ„åç§°"].astype(str).str.strip().replace({
                "": "æœªæŒ‡å®šç‰©èµ„", "nan": "æœªæŒ‡å®šç‰©èµ„", "None": "æœªæŒ‡å®šç‰©èµ„", None: "æœªæŒ‡å®šç‰©èµ„"})

            df[AppConfig.PROJECT_COLUMN] = df.iloc[:, 17].astype(str).str.strip().replace({
                "": "æœªæŒ‡å®šé¡¹ç›®éƒ¨", "nan": "æœªæŒ‡å®šé¡¹ç›®éƒ¨", "None": "æœªæŒ‡å®šé¡¹ç›®éƒ¨", None: "æœªæŒ‡å®šé¡¹ç›®éƒ¨"})

            df["ä¸‹å•æ—¶é—´"] = pd.to_datetime(df["ä¸‹å•æ—¶é—´"], errors='coerce').dt.tz_localize(None)
            df = df[~df["ä¸‹å•æ—¶é—´"].isna()]

            df["éœ€æ±‚é‡"] = safe_convert_to_numeric(df["éœ€æ±‚é‡"]).astype(int)
            df["å·²å‘é‡"] = safe_convert_to_numeric(df.get("å·²å‘é‡", 0)).astype(int)
            df["å‰©ä½™é‡"] = (df["éœ€æ±‚é‡"] - df["å·²å‘é‡"]).clip(lower=0).astype(int)

            if "è®¡åˆ’è¿›åœºæ—¶é—´" in df.columns:
                df["è®¡åˆ’è¿›åœºæ—¶é—´"] = pd.to_datetime(df["è®¡åˆ’è¿›åœºæ—¶é—´"], errors='coerce').dt.tz_localize(None)
            
            try:
                df["è¶…æœŸå¤©æ•°"] = safe_convert_to_numeric(df.iloc[:, 15]).astype(int)
            except Exception:
                df["è¶…æœŸå¤©æ•°"] = 0

            return df
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return pd.DataFrame()


@st.cache_data(ttl=3600)
def load_logistics_data():
    data_path = find_data_file()
    if not data_path:
        return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])

    try:
        with st.spinner("æ­£åœ¨åŠ è½½ç‰©æµæ•°æ®..."):
            try:
                df = pd.read_excel(data_path, sheet_name=AppConfig.LOGISTICS_SHEET_NAME, engine='openpyxl')
                
                # å¼ºåˆ¶ä» Gåˆ— (ç´¢å¼•6) è¯»å–æ•°æ®ä½œä¸º "å¸è´§åœ°å€"
                if df.shape[1] > 6:
                    df["å¸è´§åœ°å€"] = df.iloc[:, 6].astype(str).replace({"nan": "", "None": ""})
                else:
                    df["å¸è´§åœ°å€"] = ""
                    
            except Exception:
                return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])

            if df.empty:
                return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])

            for col in AppConfig.LOGISTICS_COLUMNS:
                if col not in df.columns:
                    df[col] = "" if col != "æ•°é‡" else 0

            df["ç‰©èµ„åç§°"] = df["ç‰©èµ„åç§°"].astype(str).str.strip().replace({
                "": "æœªæŒ‡å®šç‰©èµ„", "nan": "æœªæŒ‡å®šç‰©èµ„", "None": "æœªæŒ‡å®šç‰©èµ„", None: "æœªæŒ‡å®šç‰©èµ„"})
            df["é’¢å‚"] = df["é’¢å‚"].astype(str).str.strip().replace({
                "": "æœªæŒ‡å®šé’¢å‚", "nan": "æœªæŒ‡å®šé’¢å‚", "None": "æœªæŒ‡å®šé’¢å‚", None: "æœªæŒ‡å®šé’¢å‚"})
            df["é¡¹ç›®éƒ¨"] = df["é¡¹ç›®éƒ¨"].astype(str).str.strip().replace({
                "æœªæŒ‡å®šé¡¹ç›®éƒ¨": "", "nan": "", "None": "", None: ""})

            df = df[df["é¡¹ç›®éƒ¨"] != ""]

            def safe_convert_numeric(series):
                if series.dtype == 'object':
                    cleaned = series.astype(str).str.replace(r'[^\d.-]', '', regex=True)
                    cleaned = cleaned.replace({'': '0', 'nan': '0', 'None': '0', ' ': '0'})
                    return pd.to_numeric(cleaned, errors='coerce').fillna(0)
                else:
                    return pd.to_numeric(series, errors='coerce').fillna(0)

            df["æ•°é‡"] = safe_convert_numeric(df["æ•°é‡"])
            df["äº¤è´§æ—¶é—´"] = pd.to_datetime(df["äº¤è´§æ—¶é—´"], errors="coerce")
            df["è”ç³»æ–¹å¼"] = df["è”ç³»æ–¹å¼"].astype(str)
            if "å¸è´§åœ°å€" in df.columns:
                df["å¸è´§åœ°å€"] = df["å¸è´§åœ°å€"].astype(str).replace({"nan": "", "None": ""})

            df["record_id"] = df.apply(generate_record_id, axis=1)

            return df[AppConfig.LOGISTICS_COLUMNS + ["record_id"]]

    except Exception as e:
        st.error(f"ç‰©æµæ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])


# ==================== ç‰©æµçŠ¶æ€ç®¡ç† ====================
def load_logistics_status():
    if os.path.exists(AppConfig.LOGISTICS_STATUS_FILE):
        try:
            status_df = pd.read_csv(AppConfig.LOGISTICS_STATUS_FILE)
            if "record_id" not in status_df.columns:
                status_df["record_id"] = ""
            if "update_time" not in status_df.columns:
                status_df["update_time"] = datetime.now().strftime(AppConfig.DATE_FORMAT)
            if "ç‰©æµä¿¡æ¯" in status_df.columns:
                status_df = status_df.drop(columns=["ç‰©æµä¿¡æ¯"])
            return status_df
        except Exception:
            return pd.DataFrame(columns=["record_id", "åˆ°è´§çŠ¶æ€", "update_time"])
    return pd.DataFrame(columns=["record_id", "åˆ°è´§çŠ¶æ€", "update_time"])


def save_logistics_status(status_df):
    try:
        status_df.to_csv(AppConfig.LOGISTICS_STATUS_FILE, index=False, encoding='utf-8-sig')
        return True
    except Exception:
        return False


def merge_logistics_with_status(logistics_df):
    if logistics_df.empty:
        return logistics_df

    status_df = load_logistics_status()
    current_date = datetime.now().date()
    three_days_ago = current_date - timedelta(days=3)
    
    if status_df.empty:
        logistics_df["åˆ°è´§çŠ¶æ€"] = logistics_df.apply(
            lambda row: "å·²åˆ°è´§" if (
                pd.notna(row["äº¤è´§æ—¶é—´"]) and 
                row["äº¤è´§æ—¶é—´"].date() < three_days_ago
            ) else "é’¢å‚å·²æ¥å•",
            axis=1
        )
        return logistics_df

    required_status_cols = ["record_id", "åˆ°è´§çŠ¶æ€"]
    for col in required_status_cols:
        if col not in status_df.columns:
            status_df[col] = ""
    
    merged = pd.merge(
        logistics_df,
        status_df[required_status_cols],
        on="record_id",
        how="left",
        suffixes=("", "_status")
    )
    
    if "åˆ°è´§çŠ¶æ€_status" in merged.columns:
        mask_no_status = merged["åˆ°è´§çŠ¶æ€_status"].isna()
        mask_old_delivery = merged["äº¤è´§æ—¶é—´"].apply(
            lambda x: pd.notna(x) and x.date() < three_days_ago
        )
        
        merged.loc[mask_no_status & mask_old_delivery, "åˆ°è´§çŠ¶æ€"] = "å·²åˆ°è´§"
        merged.loc[mask_no_status & ~mask_old_delivery, "åˆ°è´§çŠ¶æ€"] = "é’¢å‚å·²æ¥å•"
        merged.loc[~mask_no_status, "åˆ°è´§çŠ¶æ€"] = merged.loc[~mask_no_status, "åˆ°è´§çŠ¶æ€_status"]
        merged = merged.drop(columns=["åˆ°è´§çŠ¶æ€_status"])
    else:
        merged["åˆ°è´§çŠ¶æ€"] = merged.apply(
            lambda row: "å·²åˆ°è´§" if (
                pd.notna(row["äº¤è´§æ—¶é—´"]) and 
                row["äº¤è´§æ—¶é—´"].date() < three_days_ago
            ) else "é’¢å‚å·²æ¥å•",
            axis=1
        )
    
    return merged


def update_logistics_status(record_id, new_status, original_row=None):
    try:
        status_df = load_logistics_status()
        new_status = str(new_status).strip() if new_status else "å…¬å¸ç»Ÿç­¹ä¸­"

        send_notification = False
        if new_status == "æœªåˆ°è´§":
            existing_status = status_df.loc[status_df["record_id"] == record_id, "åˆ°è´§çŠ¶æ€"]
            if len(existing_status) == 0 or existing_status.iloc[0] != "æœªåˆ°è´§":
                send_notification = True

        if record_id in status_df["record_id"].values:
            status_df.loc[status_df["record_id"] == record_id, "åˆ°è´§çŠ¶æ€"] = new_status
            status_df.loc[status_df["record_id"] == record_id, "update_time"] = datetime.now().strftime(AppConfig.DATE_FORMAT)
        else:
            new_record = pd.DataFrame([{
                "record_id": record_id,
                "åˆ°è´§çŠ¶æ€": new_status,
                "update_time": datetime.now().strftime(AppConfig.DATE_FORMAT)
            }])
            status_df = pd.concat([status_df, new_record], ignore_index=True)

        if save_logistics_status(status_df):
            if send_notification and original_row is not None:
                material_info = {
                    "ç‰©èµ„åç§°": original_row["ç‰©èµ„åç§°"],
                    "è§„æ ¼å‹å·": original_row["è§„æ ¼å‹å·"],
                    "æ•°é‡": original_row["æ•°é‡"],
                    "äº¤è´§æ—¶é—´": original_row["äº¤è´§æ—¶é—´"].strftime("%Y-%m-%d %H:%M") if pd.notna(original_row["äº¤è´§æ—¶é—´"]) else "æœªçŸ¥",
                    "é¡¹ç›®éƒ¨": original_row["é¡¹ç›®éƒ¨"]
                }
                if send_feishu_notification(material_info):
                    st.toast("å·²å‘é€ç‰©æµå¼‚å¸¸é€šçŸ¥", icon="ğŸ“¨")
            return True
        return False
    except Exception:
        return False


def batch_update_logistics_status(record_ids, new_status, original_rows=None):
    try:
        status_df = load_logistics_status()
        new_status = str(new_status).strip() if new_status else "å…¬å¸ç»Ÿç­¹ä¸­"
        success_count = 0
        
        for i, record_id in enumerate(record_ids):
            try:
                original_row = original_rows[i] if original_rows and i < len(original_rows) else None
                send_notification = False
                if new_status == "æœªåˆ°è´§":
                    existing_status = status_df.loc[status_df["record_id"] == record_id, "åˆ°è´§çŠ¶æ€"]
                    if len(existing_status) == 0 or existing_status.iloc[0] != "æœªåˆ°è´§":
                        send_notification = True

                if record_id in status_df["record_id"].values:
                    status_df.loc[status_df["record_id"] == record_id, "åˆ°è´§çŠ¶æ€"] = new_status
                    status_df.loc[status_df["record_id"] == record_id, "update_time"] = datetime.now().strftime(AppConfig.DATE_FORMAT)
                else:
                    new_record = pd.DataFrame([{
                        "record_id": record_id,
                        "åˆ°è´§çŠ¶æ€": new_status,
                        "update_time": datetime.now().strftime(AppConfig.DATE_FORMAT)
                    }])
                    status_df = pd.concat([status_df, new_record], ignore_index=True)

                if send_notification and original_row is not None:
                    material_info = {
                        "ç‰©èµ„åç§°": original_row["ç‰©èµ„åç§°"],
                        "è§„æ ¼å‹å·": original_row["è§„æ ¼å‹å·"],
                        "æ•°é‡": original_row["æ•°é‡"],
                        "äº¤è´§æ—¶é—´": original_row["äº¤è´§æ—¶é—´"].strftime("%Y-%m-%d %H:%M") if pd.notna(original_row["äº¤è´§æ—¶é—´"]) else "æœªçŸ¥",
                        "é¡¹ç›®éƒ¨": original_row["é¡¹ç›®éƒ¨"]
                    }
                    send_feishu_notification(material_info)
                success_count += 1
            except Exception:
                continue

        if save_logistics_status(status_df):
            return success_count, 0
        return 0, len(record_ids)
    except Exception:
        return 0, len(record_ids)


# ==================== URLå‚æ•°å¤„ç† ====================
def handle_url_parameters():
    query_params = st.query_params
    if 'project' in query_params:
        project_key = query_params['project']
        if isinstance(project_key, list):
            project_key = project_key[0].lower()
        else:
            project_key = project_key.lower()
            
        project_name = AppConfig.PROJECT_MAPPING.get(project_key, "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸")
        valid_projects = get_valid_projects()
        
        if project_name in valid_projects:
            st.session_state.project_selected = True
            st.session_state.selected_project = project_name
            if project_name == "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸":
                st.session_state.need_password = True
            else:
                if 'need_password' in st.session_state: del st.session_state['need_password']
                if 'temp_selected_project' in st.session_state: del st.session_state['temp_selected_project']


def get_valid_projects():
    logistics_df = load_logistics_data()
    valid_projects = ["ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸"]
    if not logistics_df.empty:
        current_date = datetime.now().date()
        start_date = current_date - timedelta(days=15)
        end_date = current_date + timedelta(days=15)
        logistics_df = logistics_df.dropna(subset=['äº¤è´§æ—¶é—´'])
        logistics_df['äº¤è´§æ—¥æœŸ'] = logistics_df['äº¤è´§æ—¶é—´'].dt.date
        mask = (logistics_df['äº¤è´§æ—¥æœŸ'] >= start_date) & (logistics_df['äº¤è´§æ—¥æœŸ'] <= end_date)
        project_list = sorted([p for p in logistics_df[mask]["é¡¹ç›®éƒ¨"].unique() if p != ""])
        valid_projects.extend(project_list)
    return valid_projects


# ==================== é¡µé¢ç»„ä»¶ ====================
def show_logistics_tab(project):
    yesterday = datetime.now().date() - timedelta(days=1)
    col1, col2 = st.columns(2)
    with col1:
        start = st.date_input("å¼€å§‹æ—¥æœŸ", yesterday, key="logistics_start")
    with col2:
        end = st.date_input("ç»“æŸæ—¥æœŸ", yesterday, key="logistics_end")

    if start > end:
        st.error("ç»“æŸæ—¥æœŸä¸èƒ½æ—©äºå¼€å§‹æ—¥æœŸ")
        return

    with st.spinner("åŠ è½½ç‰©æµä¿¡æ¯..."):
        df = load_logistics_data()
        if project != "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸":
            df = df[df["é¡¹ç›®éƒ¨"] == project]

        if not df.empty:
            df = merge_logistics_with_status(df)
            mask = (df["äº¤è´§æ—¶é—´"] >= pd.to_datetime(start)) & (df["äº¤è´§æ—¶é—´"] < pd.to_datetime(end) + timedelta(days=1))
            filtered = df[mask].copy()

            st.markdown('<div class="metric-container">', unsafe_allow_html=True)
            
            overdue = filtered['åˆ°è´§çŠ¶æ€'].eq('æœªåˆ°è´§').sum()
            total = len(filtered)
            arrived = filtered['åˆ°è´§çŠ¶æ€'].eq('å·²åˆ°è´§').sum()
            progress = total - arrived - overdue

            cols = st.columns(4)
            metrics = [
                ("ğŸ“¦", "æ€»ç‰©æµå•æ•°", total, "å•"),
                ("âœ…", "å·²åˆ°è´§å•æ•°", arrived, "å•"),
                ("ğŸ”„", "è¿›è¡Œä¸­è®¢å•", progress, "å•"),
                ("âš ï¸", "æœªåˆ°è´§è®¢å•", overdue, "å•")
            ]

            for i, m in enumerate(metrics):
                with cols[i]:
                    st.markdown(f"""
                    <div class="metric-card">
                        <div style="display:flex;align-items:center;gap:5px">
                            <span style="font-size:1.2rem">{m[0]}</span>
                            <strong>{m[1]}</strong>
                        </div>
                        <div class="card-value">{m[2]}</div>
                    </div>
                    """, unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

            st.markdown("##### ğŸ“¦ æ‰¹é‡çŠ¶æ€æ›´æ–°")
            b_col1, b_col2, b_col3 = st.columns([2, 2, 1])
            with b_col1:
                record_map = {f"{r['ç‰©èµ„åç§°']} - {r['è§„æ ¼å‹å·']} - {r['é’¢å‚']} - {r['æ•°é‡']}å¨": r['record_id'] for _, r in filtered.iterrows()}
                sel_recs = st.multiselect("é€‰æ‹©è®°å½•", options=list(record_map.keys()))
            with b_col2:
                new_st = st.selectbox("æ–°çŠ¶æ€", AppConfig.STATUS_OPTIONS)
            with b_col3:
                st.write("")
                st.write("")
                if st.button("ğŸš€ æ›´æ–°", type="primary") and sel_recs:
                    ids = [record_map[k] for k in sel_recs]
                    rows = [filtered[filtered['record_id'] == i].iloc[0] for i in ids]
                    s, e = batch_update_logistics_status(ids, new_st, rows)
                    if s > 0: st.success(f"å·²æ›´æ–° {s} æ¡")
                    st.rerun()

            disp_cols = [c for c in filtered.columns if c not in ["record_id", "æ”¶è´§åœ°å€"]]
            disp_df = filtered[disp_cols].reset_index(drop=True)
            
            st.markdown("**ç‰©æµæ˜ç»†è¡¨** (ä¿®æ”¹è‡ªåŠ¨ä¿å­˜)")
            edited = st.data_editor(
                disp_df,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "åˆ°è´§çŠ¶æ€": st.column_config.SelectboxColumn("åˆ°è´§çŠ¶æ€", options=AppConfig.STATUS_OPTIONS, required=True),
                    "æ•°é‡": st.column_config.NumberColumn("æ•°é‡", format="%d"),
                    "äº¤è´§æ—¶é—´": st.column_config.DatetimeColumn("äº¤è´§æ—¶é—´", format="YYYY-MM-DD HH:mm"),
                    "å¸è´§åœ°å€": st.column_config.TextColumn("å¸è´§åœ°å€"),
                    "å¤‡æ³¨": st.column_config.TextColumn("å¤‡æ³¨", width="large"),
                },
                key=f"logistics_editor_{project}"
            )
            auto_process_logistics_changes(edited, filtered, project)
            
            st.markdown('<div class="remark-card logistics-remark"><div class="remark-content">ğŸ“¢ ä»¥ä¸Šæ•°æ®ä¸ºå…¬å¸å·²å®‰æ’çš„å‘è´§æƒ…å†µ</div></div>', unsafe_allow_html=True)
        else:
            st.info("ğŸ“­ å½“å‰æ²¡æœ‰ç‰©æµæ•°æ®")


def auto_process_logistics_changes(edited_df, original_filtered_df, project):
    if f'logistics_editor_{project}' not in st.session_state: return
    changed = st.session_state[f'logistics_editor_{project}'].get('edited_rows', {})
    if not changed: return

    pkey = f"processed_changes_{project}"
    if pkey not in st.session_state: st.session_state[pkey] = set()

    count = 0
    for idx_str, changes in changed.items():
        chash = f"{idx_str}_{changes.get('åˆ°è´§çŠ¶æ€', '')}"
        if chash not in st.session_state[pkey]:
            st.session_state[pkey].add(chash)
            try:
                idx = int(idx_str)
                if idx < len(original_filtered_df):
                    rec_id = original_filtered_df.iloc[idx]["record_id"]
                    orig = original_filtered_df.iloc[idx]
                    nst = changes.get("åˆ°è´§çŠ¶æ€", orig["åˆ°è´§çŠ¶æ€"])
                    if nst != orig["åˆ°è´§çŠ¶æ€"]:
                        if update_logistics_status(rec_id, nst, orig):
                            count += 1
                            st.toast(f"âœ… {orig['ç‰©èµ„åç§°']} çŠ¶æ€æ›´æ–°", icon="ok")
            except: pass
    
    if count > 0:
        time.sleep(1)
        st.rerun()


def show_interactive_analysis(df):
    """æˆ˜æœ¯é›·è¾¾ï¼šä¾›éœ€è„‰å†²çŸ©é˜µ (Tactical Pulse Matrix)"""
    
    # 1. æ ‡é¢˜ä¸é£æ ¼å®šä¹‰
    st.markdown("""
        <div style="text-align: center; margin-bottom: 1rem;">
            <h1 style="
                background: linear-gradient(to right, #00f260, #0575e6);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                font-size: 2.5rem;
                font-weight: 800;
                letter-spacing: 2px;
            ">TACTICAL SUPPLY RADAR</h1>
            <p style="color: #888; font-family: monospace; letter-spacing: 3px; font-size: 0.9rem;">
                >>> SUPPLY-DEMAND MATRIX MONITORING SYSTEM <<<
            </p>
        </div>
    """, unsafe_allow_html=True)
    
    # 2. ç­›é€‰å™¨
    with st.expander("âš™ï¸ é›·è¾¾å‚æ•°è®¾ç½® / ç­›é€‰", expanded=False):
        all_factories = ["å…¨éƒ¨"] + sorted(list(df["é’¢å‚"].unique()))
        # ä¼˜å…ˆä½¿ç”¨å¸è´§åœ°å€ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é¡¹ç›®éƒ¨
        if "å¸è´§åœ°å€" in df.columns:
            # å¡«å……ç©ºåœ°å€ä¸ºé¡¹ç›®éƒ¨åç§°
            df["æ˜¾ç¤ºåœ°å€"] = df["å¸è´§åœ°å€"].replace("", None).fillna(df["é¡¹ç›®éƒ¨"])
        else:
            df["æ˜¾ç¤ºåœ°å€"] = df["é¡¹ç›®éƒ¨"]
            
        all_addresses = ["å…¨éƒ¨"] + sorted(list(df["æ˜¾ç¤ºåœ°å€"].unique()))
        
        c1, c2 = st.columns(2)
        with c1:
            sel_factories = st.multiselect("ğŸ­ ä¾›æ–¹ (é’¢å‚)", all_factories, default="å…¨éƒ¨")
        with c2:
            sel_addresses = st.multiselect("ğŸ“ éœ€æ–¹ (å¸è´§åœ°å€)", all_addresses, default="å…¨éƒ¨")

    # 3. æ•°æ®è¿‡æ»¤
    filtered_df = df.copy()
    if "å…¨éƒ¨" not in sel_factories and sel_factories:
        filtered_df = filtered_df[filtered_df["é’¢å‚"].isin(sel_factories)]
    if "å…¨éƒ¨" not in sel_addresses and sel_addresses:
        filtered_df = filtered_df[filtered_df["æ˜¾ç¤ºåœ°å€"].isin(sel_addresses)]
        
    if filtered_df.empty:
        st.warning("âš ï¸ æš‚æ— ç›‘æ§æ•°æ®")
        return

    # 4. åŠ¨ç”»æ•°æ®å‡†å¤‡
    anim_df = filtered_df[["äº¤è´§æ—¶é—´", "é’¢å‚", "æ˜¾ç¤ºåœ°å€", "æ•°é‡", "ç‰©èµ„åç§°"]].copy()
    anim_df["æ—¥æœŸ"] = anim_df["äº¤è´§æ—¶é—´"].dt.date
    
    # æŒ‰å¤©ã€é’¢å‚ã€åœ°å€æ±‡æ€» (æ¯å¤©å¯èƒ½æœ‰å¤šä¸ªç‰©èµ„ï¼Œè¿™é‡ŒæŒ‰ç‰©èµ„ç±»å‹ç€è‰²)
    grouped = anim_df.groupby(["æ—¥æœŸ", "é’¢å‚", "æ˜¾ç¤ºåœ°å€", "ç‰©èµ„åç§°"])["æ•°é‡"].sum().reset_index()
    
    # ç¡®ä¿æ—¥æœŸè¿ç»­ (ä¸ºäº†åŠ¨ç”»æµç•…ï¼Œå³ä½¿æŸå¤©æ²¡æ•°æ®ä¹Ÿè¦æœ‰å¸§)
    if not grouped.empty:
        min_date = grouped["æ—¥æœŸ"].min()
        max_date = grouped["æ—¥æœŸ"].max()
        # å¦‚æœè·¨åº¦å¤ªå¤§ï¼Œé™åˆ¶ä¸€ä¸‹ï¼Œé¿å…æ¸²æŸ“å¤ªæ…¢
        if (max_date - min_date).days > 60:
            min_date = max_date - timedelta(days=60)
            grouped = grouped[grouped["æ—¥æœŸ"] >= min_date]
            
        grouped["æ—¥æœŸStr"] = grouped["æ—¥æœŸ"].astype(str)
        
        # 5. ç»˜åˆ¶è„‰å†²çŸ©é˜µ
        fig = px.scatter(
            grouped,
            x="é’¢å‚",
            y="æ˜¾ç¤ºåœ°å€",
            size="æ•°é‡",
            color="ç‰©èµ„åç§°",
            animation_frame="æ—¥æœŸStr",
            animation_group="æ˜¾ç¤ºåœ°å€",
            size_max=50, # æ°”æ³¡æœ€å¤§å°ºå¯¸
            hover_name="ç‰©èµ„åç§°",
            range_x=[-0.5, len(grouped["é’¢å‚"].unique()) - 0.5], # ç¨å¾®ç•™è¾¹
            # ä½¿ç”¨é²œè‰³çš„éœ“è™¹é…è‰²
            color_discrete_sequence=px.colors.qualitative.Vivid
        )
        
        # 6. é«˜ç§‘æŠ€æš—é»‘é£æ ¼å®šåˆ¶
        fig.update_layout(
            template="plotly_dark", # æš—é»‘åº•è‰²
            height=700,
            paper_bgcolor='rgba(0,0,0,0)', # é€æ˜èƒŒæ™¯èå…¥ç½‘é¡µ
            plot_bgcolor='rgba(10,10,20,0.8)', # æ·±è“é»‘ç»˜å›¾åŒº
            xaxis=dict(
                title="SUPPLIER (SOURCE)",
                showgrid=True,
                gridcolor='rgba(255,255,255,0.1)', # éšçº¦çš„ç½‘æ ¼
                tickfont=dict(size=12, color="#00f260")
            ),
            yaxis=dict(
                title="DESTINATION (TARGET)",
                showgrid=True,
                gridcolor='rgba(255,255,255,0.1)',
                tickfont=dict(size=12, color="#00f260")
            ),
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            margin=dict(l=0, r=0, t=50, b=0),
            # æ’­æ”¾æŒ‰é’®æ ·å¼
            updatemenus=[{
                "type": "buttons",
                "showactive": False,
                "x": 0.05, "y": 1.15,
                "buttons": [{
                    "label": "â–¶ ACTIVATE RADAR",
                    "method": "animate",
                    "args": [None, {"frame": {"duration": 300, "redraw": True}, "fromcurrent": True}]
                }]
            }]
        )
        
        # å»æ‰X/Yè½´çš„é›¶çº¿ï¼Œè®©ç½‘æ ¼æ›´çº¯ç²¹
        fig.update_xaxes(zeroline=False)
        fig.update_yaxes(zeroline=False)
        
        # æ—¶é—´æ»‘å—æ ·å¼
        fig.layout.sliders[0].currentvalue = {
            "prefix": "MONITORING DATE: ", 
            "font": {"size": 20, "color": "#00f260", "family": "monospace"}
        }
        fig.layout.sliders[0].pad = {"t": 50}
        
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("""
            <div style="text-align: center; margin-top: -10px; color: #666; font-size: 12px; font-family: monospace;">
                [SYSTEM STATUS: ONLINE] â€¢ DATA REFRESH RATE: REAL-TIME
            </div>
        """, unsafe_allow_html=True)
        
    else:
        st.info("ğŸ“‰ å½“å‰æ—¶é—´æ®µå†…æ— å‘è´§è®°å½•")


def show_data_panel(df, project):
    st.title(f"{project} - å‘è´§æ•°æ®")
    
    col1, col2 = st.columns([1, 6])
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°"):
            st.cache_data.clear()
            st.rerun()
    with col2:
        if st.button("ğŸ  è¿”å›é¦–é¡µ"):
            st.session_state.project_selected = False
            st.rerun()

    if project == "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸":
        analysis_df = load_logistics_data()
        tabs = ["ğŸ“‹ å‘è´§è®¡åˆ’", "ğŸš› ç‰©æµæ˜ç»†", "ğŸ“Š é™æ€ç»Ÿè®¡", "ğŸš€ æ•°æ®é©¾é©¶èˆ±"]
    else:
        full = load_logistics_data()
        analysis_df = full[full["é¡¹ç›®éƒ¨"] == project]
        tabs = ["ğŸ“‹ å‘è´§è®¡åˆ’", "ğŸš› ç‰©æµæ˜ç»†", "ğŸš€ æ•°æ®é©¾é©¶èˆ±"]
    
    if not analysis_df.empty:
        analysis_df = merge_logistics_with_status(analysis_df)

    selected_tabs = st.tabs(tabs)

    with selected_tabs[0]:
        show_plan_tab(df, project)
    
    with selected_tabs[1]:
        show_logistics_tab(project)
        
    if project == "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸":
        with selected_tabs[2]:
            show_statistics_tab(df)
        with selected_tabs[3]:
            show_interactive_analysis(analysis_df)
    else:
        with selected_tabs[2]:
            show_interactive_analysis(analysis_df)


def show_plan_tab(df, project):
    col1, col2 = st.columns(2)
    with col1: start = st.date_input("å¼€å§‹", datetime.now(), key="ps")
    with col2: end = st.date_input("ç»“æŸ", datetime.now(), key="pe")
    
    filtered = df if project == "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸" else df[df[AppConfig.PROJECT_COLUMN] == project]
    mask = (filtered["ä¸‹å•æ—¶é—´"].dt.date >= start) & (filtered["ä¸‹å•æ—¶é—´"].dt.date <= end)
    res = filtered[mask]
    
    if not res.empty:
        cols = {
            "æ ‡æ®µåç§°": "å·¥ç¨‹æ ‡æ®µ", "ç‰©èµ„åç§°": "ææ–™åç§°", "è§„æ ¼å‹å·": "è§„æ ¼å‹å·",
            "éœ€æ±‚é‡": "éœ€æ±‚(å¨)", "å·²å‘é‡": "å·²å‘(å¨)", "å‰©ä½™é‡": "å¾…å‘(å¨)",
            "è¶…æœŸå¤©æ•°": "è¶…æœŸå¤©æ•°", "ä¸‹å•æ—¶é—´": "ä¸‹å•", "è®¡åˆ’è¿›åœºæ—¶é—´": "è®¡åˆ’è¿›åœº"
        }
        disp = res[list(cols.keys())].rename(columns=cols)
        st.dataframe(disp, use_container_width=True, hide_index=True)
    else:
        st.info("æ— æ•°æ®")


def show_statistics_tab(df):
    st.subheader("ğŸ“Š æ•°æ®ç»Ÿè®¡")
    log_df = load_logistics_data()
    if log_df.empty: return
    
    grp = log_df.groupby(['é¡¹ç›®éƒ¨', 'é’¢å‚'])['æ•°é‡'].sum().reset_index()
    st.dataframe(grp, use_container_width=True)


def show_project_selection(df):
    st.markdown("<h1 style='text-align: center;'>é’¢ç­‹å‘è´§ç›‘æ§ç³»ç»Ÿ</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: gray;'>ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸</p>", unsafe_allow_html=True)
    
    c1, c2 = st.columns(2)
    with c1:
        st.info("ğŸ—ï¸ **é¡¹ç›®ç›‘æ§**\n\nå®æ—¶æŸ¥çœ‹å„é¡¹ç›®è¿›åº¦")
    with c2:
        st.success("ğŸšš **ç‰©æµè·Ÿè¸ª**\n\næŒæ¡ç‰©èµ„å‘è¿çŠ¶æ€")
        
    st.divider()
    
    log_df = load_logistics_data()
    projs = []
    if not log_df.empty:
        projs = sorted([p for p in log_df["é¡¹ç›®éƒ¨"].unique() if p])
        
    sel = st.selectbox("é€‰æ‹©é¡¹ç›®éƒ¨", ["ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸"] + projs)
    
    if st.button("è¿›å…¥ç³»ç»Ÿ", type="primary", use_container_width=True):
        if sel == "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸":
            st.session_state.temp = sel
            st.session_state.pwd = True
        else:
            st.session_state.project_selected = True
            st.session_state.selected_project = sel
            st.rerun()
            
    if st.session_state.get('pwd', False):
        p = st.text_input("å¯†ç ", type="password")
        if st.button("ç¡®è®¤"):
            if p == "123456":
                st.session_state.project_selected = True
                st.session_state.selected_project = st.session_state.temp
                del st.session_state['pwd']
                st.rerun()
            else:
                st.error("å¯†ç é”™è¯¯")


def main():
    st.set_page_config(layout="wide", page_title="å‘è´§ç›‘æ§", page_icon="ğŸ—ï¸")
    apply_card_styles()
    
    if 'project_selected' not in st.session_state: st.session_state.project_selected = False
    handle_url_parameters()
    
    df = load_data()
    
    if not st.session_state.project_selected:
        show_project_selection(df)
    else:
        show_data_panel(df, st.session_state.selected_project)

if __name__ == "__main__":
    main()
