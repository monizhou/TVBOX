# -*- coding: utf-8 -*-
"""é’¢ç­‹å‘è´§ç›‘æ§ç³»ç»Ÿï¼ˆä¸­é“æ€»éƒ¨è§†å›¾ç‰ˆï¼‰- ç‰©æµçŠ¶æ€ç‹¬ç«‹å­˜å‚¨ç‰ˆ"""
import os
import re
import time
from datetime import datetime, timedelta
import pandas as pd
import streamlit as st
import requests
import hashlib
import json


# ==================== ç³»ç»Ÿé…ç½® ====================
class AppConfig:
    DATA_PATHS = [
        os.path.join(os.path.dirname(__file__), "å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsm"),
        os.path.join(os.path.dirname(__file__), "å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsx"),
        r"F:\1.ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸-å››å·ç‰©ä¾›ä¸­å¿ƒ\é’¢æ-ç»“ç®—\é’¢ç­‹å‘è´§è®¡åˆ’-å‘ä¸å°åˆš\å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsx",
        r"D:\PyCharm\PycharmProjects\project\å‘è´§è®¡åˆ’ï¼ˆå®œå®¾é¡¹ç›®ï¼‰æ±‡æ€».xlsx"
    ]

    # å¯èƒ½çš„ç‰©æµå·¥ä½œè¡¨åç§°
    LOGISTICS_SHEET_NAMES = ["ç‰©æµæ˜ç»†", "ç‰©æµä¿¡æ¯", "å‘è´§æ˜ç»†", "è¿è¾“æ˜ç»†", "ç‰©æµæ•°æ®"]
    LOGISTICS_COLUMNS = [
        "é’¢å‚", "ç‰©èµ„åç§°", "è§„æ ¼å‹å·", "å•ä½", "æ•°é‡",
        "äº¤è´§æ—¶é—´", "æ”¶è´§åœ°å€", "è”ç³»äºº", "è”ç³»æ–¹å¼", "é¡¹ç›®éƒ¨",
        "åˆ°è´§çŠ¶æ€", "ç‰©æµä¿¡æ¯"
    ]

    DATE_FORMAT = "%Y-%m-%d"
    BACKUP_COL_MAPPING = {
        'æ ‡æ®µåç§°': ['é¡¹ç›®æ ‡æ®µ', 'å·¥ç¨‹åç§°', 'æ ‡æ®µ'],
        'ç‰©èµ„åç§°': ['ææ–™åç§°', 'å“å', 'åç§°'],
        'éœ€æ±‚é‡': ['éœ€æ±‚å¨ä½', 'è®¡åˆ’é‡', 'æ•°é‡'],
        'ä¸‹å•æ—¶é—´': ['åˆ›å»ºæ—¶é—´', 'æ—¥æœŸ', 'å½•å…¥æ—¶é—´']
    }
    WEBHOOK_URL = "https://open.feishu.cn/open-apis/bot/v2/hook/dcf16af3-78d2-433f-9c3d-b4cd108c7b60"
    LOGISTICS_DATE_RANGE_DAYS = 5

    LOGISTICS_STATUS_FILE = "logistics_status.csv"
    # æ›´æ–°çŠ¶æ€é€‰é¡¹ï¼ŒåŒ…å«å®Œæ•´çš„å‘è´§æµç¨‹
    STATUS_OPTIONS = ["å…¬å¸ç»Ÿç­¹ä¸­", "é’¢å‚å·²æ¥å•", "è¿è¾“ä¸­", "å·²åˆ°è´§", "æœªåˆ°è´§"]
    PROJECT_COLUMN = "é¡¹ç›®éƒ¨åç§°"

    CARD_STYLES = {
        "hover_shadow": "0 8px 16px rgba(0,0,0,0.2)",
        "glass_effect": """
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(12px);
            -webkit-backdrop-filter: blur(12px);
            border-radius: 10px;
            border: 1px solid rgba(255, 255, 255, 0.18);
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
        """,
        "number_animation": """
            @keyframes countup {
                from { opacity: 0; transform: translateY(10px); }
                to { opacity: 1; transform: translateY(0); }
            }
        """,
        "floating_animation": """
            @keyframes floating {
                0% { transform: translateY(0px); }
                50% { transform: translateY(-8px); }
                100% { transform: translateY(0px); }
            }
        """,
        "pulse_animation": """
            @keyframes pulse {
                0% { transform: scale(1); }
                50% { transform: scale(1.03); }
                100% { transform: scale(1); }
            }
        """
    }


# ==================== è¾…åŠ©å‡½æ•° ====================
def find_data_file():
    """æŸ¥æ‰¾æ•°æ®æ–‡ä»¶ï¼Œå¢å¼ºç‰ˆæœ¬"""
    for path in AppConfig.DATA_PATHS:
        if os.path.exists(path):
            st.success(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {os.path.basename(path)}")
            return path

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é…ç½®çš„æ–‡ä»¶ï¼Œåˆ—å‡ºå½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰Excelæ–‡ä»¶ä¾›é€‰æ‹©
    current_dir = os.path.dirname(__file__)
    if current_dir:
        excel_files = [f for f in os.listdir(current_dir) if f.endswith(('.xlsx', '.xls', '.xlsm'))]
        if excel_files:
            st.warning(f"æœªæ‰¾åˆ°é…ç½®çš„æ•°æ®æ–‡ä»¶ï¼Œä½†å‘ç°ä»¥ä¸‹Excelæ–‡ä»¶: {', '.join(excel_files)}")
            # å°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶
            first_excel = os.path.join(current_dir, excel_files[0])
            st.info(f"å°è¯•ä½¿ç”¨: {excel_files[0]}")
            return first_excel

    st.error("âŒ æœªæ‰¾åˆ°ä»»ä½•Excelæ•°æ®æ–‡ä»¶")
    return None


def apply_card_styles():
    st.markdown(f"""
    <style>
        /* æ–°å¢å¤‡æ³¨å¡ç‰‡æ ·å¼ */
        .remark-card {{
            background: rgba(245, 245, 247, 0.9);
            border-radius: 10px;
            padding: 1rem;
            margin: 1.5rem 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            border-left: 4px solid;
        }}
        .plan-remark {{ border-color: #2196F3; }}
        .logistics-remark {{ border-color: #4CAF50; }}
        .remark-content {{
            font-size: 1rem;
            color: #666;
            text-align: center;
            padding: 1rem;
        }}

        /* è‹¹æœé£æ ¼æ ‡ç­¾é¡µ */
        .stTabs [data-baseweb="tab-list"] {{
            gap: 8px;
            padding: 8px 0;
            background: #f5f5f7;
            border-radius: 12px;
            margin: 1rem 0;
        }}

        .stTabs [data-baseweb="tab"] {{
            background: transparent !important;
            padding: 12px 24px !important;
            border: none !important;
            color: #86868b !important;
            font-size: 14px;
            font-weight: 500;
            transition: all 0.2s cubic-bezier(0.25, 0.46, 0.45, 0.94);
            border-radius: 8px;
            margin: 0 4px !important;
        }}

        .stTabs [data-baseweb="tab"]:hover {{
            background: rgba(0, 0, 0, 0.04) !important;
            color: #1d1d1f !important;
            transform: scale(1.02);
        }}

        .stTabs [aria-selected="true"] {{
            background: #ffffff !important;
            color: #1d1d1f !important;
            font-weight: 600;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.08),
                        inset 0 0 0 1px rgba(0, 0, 0, 0.04);
        }}

        .stTabs [aria-selected="true"]:hover {{
            transform: none;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1),
                        inset 0 0 0 1px rgba(0, 0, 0, 0.06);
        }}

        /* é€‚é…ç§»åŠ¨ç«¯ */
        @media (max-width: 768px) {{
            .stTabs [data-baseweb="tab-list"] {{
                flex-wrap: wrap;
            }}
            .stTabs [data-baseweb="tab"] {{
                flex: 1 1 45%;
                margin: 4px !important;
                text-align: center;
            }}
        }}
        {AppConfig.CARD_STYLES['number_animation']}
        {AppConfig.CARD_STYLES['floating_animation']}
        {AppConfig.CARD_STYLES['pulse_animation']}

        @keyframes fadeIn {{
            from {{ opacity: 0; transform: translateY(20px); }}
            to {{ opacity: 1; transform: translateY(0); }}
        }}

        .metric-container {{ 
            display: grid; 
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); 
            gap: 1rem; 
            margin: 1rem 0; 
            animation: fadeIn 0.6s ease-out;
        }}
        .metric-card {{
            {AppConfig.CARD_STYLES['glass_effect']}
            transition: all 0.3s ease;
            padding: 1.5rem;
        }}
        .metric-card:hover {{
            transform: translateY(-5px);
            box-shadow: {AppConfig.CARD_STYLES['hover_shadow']};
        }}
        .card-value {{
            font-size: 2rem;
            font-weight: 700;
            background: linear-gradient(45deg, #2c3e50, #3498db);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            animation: countup 0.8s ease-out;
            margin: 0.5rem 0;
        }}
        .card-unit {{
            font-size: 0.9rem;
            color: #666;
        }}
        .overdue-row {{ background-color: #ffdddd !important; }}
        .status-arrived {{ background-color: #ddffdd !important; }}
        .status-not-arrived {{ background-color: #ffdddd !important; }}
        .status-empty {{ background-color: transparent !important; }}

        .home-card {{
            {AppConfig.CARD_STYLES['glass_effect']}
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            transition: all 0.3s ease;
            animation: floating 4s ease-in-out infinite;
        }}
        .home-card:hover {{
            animation: pulse 1.5s infinite;
            box-shadow: {AppConfig.CARD_STYLES['hover_shadow']};
        }}
        .home-card-title {{
            font-size: 1.5rem;
            font-weight: bold;
            margin-bottom: 1rem;
            color: #2c3e50;
            border-bottom: 2px solid rgba(44, 62, 80, 0.1);
            padding-bottom: 0.5rem;
        }}
        .home-card-content {{
            font-size: 1rem;
            line-height: 1.6;
            color: #555;
        }}
        .home-card-icon {{
            font-size: 2.5rem;
            margin-bottom: 1rem;
            color: #3498db;
        }}
        .project-selector {{
            margin-top: 2rem;
            margin-bottom: 2rem;
        }}
        .welcome-header {{
            font-size: 3.5rem;
            font-weight: bold;
            margin-bottom: 1rem;
            background: linear-gradient(45deg, #2c3e50, #3498db);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            text-align: center;
        }}
        .welcome-subheader {{
            font-size: 1.5rem;
            text-align: center;
            color: #666;
            margin-bottom: 2rem;
            position: relative;
            padding-bottom: 0.5rem;
        }}
        .dataframe {{
            animation: fadeIn 0.6s ease-out;
        }}
    </style>
    """, unsafe_allow_html=True)


def generate_record_id(row):
    key_fields = [
        str(row["é’¢å‚"]),
        str(row["ç‰©èµ„åç§°"]),
        str(row["è§„æ ¼å‹å·"]),
        str(row["äº¤è´§æ—¶é—´"]),
        str(row["é¡¹ç›®éƒ¨"])
    ]
    return hashlib.md5("|".join(key_fields).encode('utf-8')).hexdigest()


def send_feishu_notification(material_info):
    message = {
        "msg_type": "interactive",
        "card": {
            "config": {"wide_screen_mode": True},
            "elements": [{
                "tag": "div",
                "text": {
                    "content": f"**ç‰©èµ„åç§°**: {material_info['ç‰©èµ„åç§°']}\n"
                               f"**è§„æ ¼å‹å·**: {material_info['è§„æ ¼å‹å·']}\n"
                               f"**æ•°é‡**: {material_info['æ•°é‡']}\n"
                               f"**äº¤è´§æ—¶é—´**: {material_info['äº¤è´§æ—¶é—´']}\n"
                               f"**é¡¹ç›®éƒ¨**: {material_info['é¡¹ç›®éƒ¨']}",
                    "tag": "lark_md"
                }
            }, {
                "tag": "hr"
            }, {
                "tag": "note",
                "elements": [{
                    "content": "âš ï¸ è¯¥ç‰©èµ„çŠ¶æ€å·²æ›´æ–°ä¸ºã€æœªåˆ°è´§ã€‘ï¼Œè¯·åŠæ—¶è·Ÿè¿›",
                    "tag": "plain_text"
                }]
            }],
            "header": {
                "template": "red",
                "title": {
                    "content": "ã€ç‰©æµçŠ¶æ€æ›´æ–°é€šçŸ¥ã€‘",
                    "tag": "plain_text"
                }
            }
        }
    }
    try:
        response = requests.post(
            AppConfig.WEBHOOK_URL,
            data=json.dumps(message),
            headers={'Content-Type': 'application/json'}
        )
        return response.status_code == 200
    except Exception as e:
        st.error(f"é£ä¹¦é€šçŸ¥å‘é€å¤±è´¥: {str(e)}")
        return False


# ==================== æ•°æ®åŠ è½½ ====================
@st.cache_data(ttl=3600)
def load_data():
    def safe_convert_to_numeric(series, default=0):
        str_series = series.astype(str)
        cleaned = str_series.str.replace(r'[^\d.-]', '', regex=True)
        cleaned = cleaned.replace({'': '0', 'nan': '0', 'None': '0'})
        return pd.to_numeric(cleaned, errors='coerce').fillna(default)

    data_path = find_data_file()
    if not data_path:
        st.error("âŒ æœªæ‰¾åˆ°å‘è´§è®¡åˆ’æ•°æ®æ–‡ä»¶")
        return pd.DataFrame()

    try:
        with st.spinner("æ­£åœ¨åŠ è½½åŸºç¡€æ•°æ®..."):
            df = pd.read_excel(data_path, engine='openpyxl')

            for std_col, alt_cols in AppConfig.BACKUP_COL_MAPPING.items():
                for alt_col in alt_cols:
                    if alt_col in df.columns and std_col not in df.columns:
                        df.rename(columns={alt_col: std_col}, inplace=True)
                        break

            REQUIRED_COLS = ['æ ‡æ®µåç§°', 'ç‰©èµ„åç§°', 'ä¸‹å•æ—¶é—´', 'éœ€æ±‚é‡']
            missing_cols = [col for col in REQUIRED_COLS if col not in df.columns]
            if missing_cols:
                st.error(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                return pd.DataFrame()

            df["ç‰©èµ„åç§°"] = df["ç‰©èµ„åç§°"].astype(str).str.strip().replace({
                "": "æœªæŒ‡å®šç‰©èµ„", "nan": "æœªæŒ‡å®šç‰©èµ„", "None": "æœªæŒ‡å®šç‰©èµ„", None: "æœªæŒ‡å®šç‰©èµ„"})

            df[AppConfig.PROJECT_COLUMN] = df.iloc[:, 17].astype(str).str.strip().replace({
                "": "æœªæŒ‡å®šé¡¹ç›®éƒ¨", "nan": "æœªæŒ‡å®šé¡¹ç›®éƒ¨", "None": "æœªæŒ‡å®šé¡¹ç›®éƒ¨", None: "æœªæŒ‡å®šé¡¹ç›®éƒ¨"})

            df["ä¸‹å•æ—¶é—´"] = pd.to_datetime(df["ä¸‹å•æ—¶é—´"], errors='coerce').dt.tz_localize(None)
            df = df[~df["ä¸‹å•æ—¶é—´"].isna()]

            df["éœ€æ±‚é‡"] = safe_convert_to_numeric(df["éœ€æ±‚é‡"]).astype(int)
            df["å·²å‘é‡"] = safe_convert_to_numeric(df.get("å·²å‘é‡", 0)).astype(int)
            df["å‰©ä½™é‡"] = (df["éœ€æ±‚é‡"] - df["å·²å‘é‡"]).clip(lower=0).astype(int)

            if "è®¡åˆ’è¿›åœºæ—¶é—´" in df.columns:
                df["è®¡åˆ’è¿›åœºæ—¶é—´"] = pd.to_datetime(df["è®¡åˆ’è¿›åœºæ—¶é—´"], errors='coerce').dt.tz_localize(None)
                df["è¶…æœŸå¤©æ•°"] = ((pd.Timestamp.now() - df["è®¡åˆ’è¿›åœºæ—¶é—´"]).dt.days.clip(lower=0).fillna(0).astype(int))
            else:
                df["è¶…æœŸå¤©æ•°"] = 0

            return df
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return pd.DataFrame()


@st.cache_data(ttl=3600)
def load_logistics_data():
    data_path = find_data_file()
    if not data_path:
        return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS)

    try:
        with st.spinner("æ­£åœ¨åŠ è½½ç‰©æµæ•°æ®..."):
            # å°è¯•è¯»å–æ‰€æœ‰å¯èƒ½çš„å·¥ä½œè¡¨åç§°
            df = None
            found_sheet = None
            
            # é¦–å…ˆå°è¯•è·å–æ‰€æœ‰å·¥ä½œè¡¨åç§°
            try:
                excel_file = pd.ExcelFile(data_path, engine='openpyxl')
                sheet_names = excel_file.sheet_names
                st.info(f"å‘ç°çš„å·¥ä½œè¡¨: {', '.join(sheet_names)}")
                
                # å°è¯•åŒ¹é…ç‰©æµå·¥ä½œè¡¨
                for sheet_name in sheet_names:
                    for possible_name in AppConfig.LOGISTICS_SHEET_NAMES:
                        if possible_name in sheet_name:
                            found_sheet = sheet_name
                            st.success(f"æ‰¾åˆ°ç‰©æµå·¥ä½œè¡¨: {found_sheet}")
                            break
                    if found_sheet:
                        break
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å·¥ä½œè¡¨ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
                if not found_sheet and sheet_names:
                    found_sheet = sheet_names[0]
                    st.warning(f"æœªæ‰¾åˆ°æ ‡å‡†ç‰©æµå·¥ä½œè¡¨ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨: {found_sheet}")
                
            except Exception as e:
                st.error(f"è¯»å–Excelæ–‡ä»¶ç»“æ„å¤±è´¥: {str(e)}")
                return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])
            
            if not found_sheet:
                st.error("Excelæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å·¥ä½œè¡¨")
                return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])
            
            # è¯»å–é€‰å®šçš„å·¥ä½œè¡¨
            try:
                df = pd.read_excel(data_path, sheet_name=found_sheet, engine='openpyxl')
                st.success(f"æˆåŠŸè¯»å–å·¥ä½œè¡¨: {found_sheet}")
            except Exception as e:
                st.error(f"è¯»å–å·¥ä½œè¡¨ {found_sheet} å¤±è´¥: {str(e)}")
                return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])

            # å¦‚æœæ‰¾ä¸åˆ°ç‰©æµæ˜ç»†è¡¨ï¼Œè¿”å›ç©ºDataFrame
            if df.empty:
                st.warning("ç‰©æµæ˜ç»†è¡¨ä¸ºç©º")
                return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])

            # æ˜¾ç¤ºåŸå§‹åˆ—åä»¥ä¾¿è°ƒè¯•
            st.info(f"åŸå§‹åˆ—å: {list(df.columns)}")

            # åˆ—åæ˜ å°„ - å¤„ç†å¯èƒ½çš„åˆ—åå˜ä½“
            column_mapping = {}
            expected_columns = AppConfig.LOGISTICS_COLUMNS
            
            for expected_col in expected_columns:
                # å°è¯•ç²¾ç¡®åŒ¹é…
                if expected_col in df.columns:
                    column_mapping[expected_col] = expected_col
                    continue
                
                # å°è¯•æ¨¡ç³ŠåŒ¹é…
                found = False
                for actual_col in df.columns:
                    # å¿½ç•¥å¤§å°å†™å’Œç©ºæ ¼å·®å¼‚
                    if (expected_col.lower().replace(" ", "") in actual_col.lower().replace(" ", "") or
                        actual_col.lower().replace(" ", "") in expected_col.lower().replace(" ", "")):
                        column_mapping[expected_col] = actual_col
                        found = True
                        st.info(f"åˆ—åæ˜ å°„: '{actual_col}' -> '{expected_col}'")
                        break
                
                if not found:
                    st.warning(f"æœªæ‰¾åˆ°åŒ¹é… '{expected_col}' çš„åˆ—")
                    # æ·»åŠ ç©ºåˆ—
                    df[expected_col] = "" if expected_col != "æ•°é‡" else 0

            # é‡å‘½ååˆ—
            df = df.rename(columns={v: k for k, v in column_mapping.items() if k != v})

            # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„åˆ—éƒ½å­˜åœ¨
            for col in AppConfig.LOGISTICS_COLUMNS:
                if col not in df.columns:
                    if col == "ç‰©æµä¿¡æ¯":
                        df[col] = ""  # ç‰©æµä¿¡æ¯åˆ—é»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
                    elif col == "æ•°é‡":
                        df[col] = 0   # æ•°é‡åˆ—é»˜è®¤ä¸º0
                    else:
                        df[col] = ""   # å…¶ä»–æ–‡æœ¬åˆ—é»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²

            # æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–
            df["ç‰©èµ„åç§°"] = df["ç‰©èµ„åç§°"].astype(str).str.strip().replace({
                "": "æœªæŒ‡å®šç‰©èµ„", "nan": "æœªæŒ‡å®šç‰©èµ„", "None": "æœªæŒ‡å®šç‰©èµ„", None: "æœªæŒ‡å®šç‰©èµ„"})
            df["é’¢å‚"] = df["é’¢å‚"].astype(str).str.strip().replace({
                "": "æœªæŒ‡å®šé’¢å‚", "nan": "æœªæŒ‡å®šé’¢å‚", "None": "æœªæŒ‡å®šé’¢å‚", None: "æœªæŒ‡å®šé’¢å‚"})
            df["é¡¹ç›®éƒ¨"] = df["é¡¹ç›®éƒ¨"].astype(str).str.strip().replace({
                "æœªæŒ‡å®šé¡¹ç›®éƒ¨": "", "nan": "", "None": "", None: ""})

            # å®‰å…¨è½¬æ¢æ•°å€¼åˆ—
            def safe_convert_numeric(series):
                if series.dtype == 'object':
                    # å¤„ç†å­—ç¬¦ä¸²ä¸­çš„é€šé…ç¬¦å’Œéæ•°å­—å­—ç¬¦
                    cleaned = series.astype(str).str.replace(r'[^\d.-]', '', regex=True)
                    cleaned = cleaned.replace({'': '0', 'nan': '0', 'None': '0', ' ': '0'})
                    return pd.to_numeric(cleaned, errors='coerce').fillna(0)
                else:
                    return pd.to_numeric(series, errors='coerce').fillna(0)

            df["æ•°é‡"] = safe_convert_numeric(df["æ•°é‡"])

            # å¤„ç†æ—¥æœŸåˆ—
            df["äº¤è´§æ—¶é—´"] = pd.to_datetime(df["äº¤è´§æ—¶é—´"], errors="coerce")

            # å¤„ç†æ–‡æœ¬åˆ—
            df["è”ç³»æ–¹å¼"] = df["è”ç³»æ–¹å¼"].astype(str)

            # ç”Ÿæˆå”¯ä¸€è®°å½•ID
            df["record_id"] = df.apply(generate_record_id, axis=1)

            return df[AppConfig.LOGISTICS_COLUMNS + ["record_id"]]

    except Exception as e:
        st.error(f"ç‰©æµæ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        # è¿”å›ä¸€ä¸ªç©ºçš„DataFrameï¼ŒåŒ…å«å¿…è¦çš„åˆ—
        return pd.DataFrame(columns=AppConfig.LOGISTICS_COLUMNS + ["record_id"])


# ==================== ç‰©æµçŠ¶æ€ç®¡ç† ====================
def load_logistics_status():
    if os.path.exists(AppConfig.LOGISTICS_STATUS_FILE):
        try:
            with st.spinner("åŠ è½½ç‰©æµçŠ¶æ€..."):
                status_df = pd.read_csv(AppConfig.LOGISTICS_STATUS_FILE)
                # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                if "record_id" not in status_df.columns:
                    status_df["record_id"] = ""
                if "åˆ°è´§çŠ¶æ€" not in status_df.columns:
                    status_df["åˆ°è´§çŠ¶æ€"] = "å…¬å¸ç»Ÿç­¹ä¸­"  # é»˜è®¤çŠ¶æ€
                if "ç‰©æµä¿¡æ¯" not in status_df.columns:
                    status_df["ç‰©æµä¿¡æ¯"] = ""  # æ–°å¢ç‰©æµä¿¡æ¯åˆ—
                if "update_time" not in status_df.columns:
                    status_df["update_time"] = datetime.now().strftime(AppConfig.DATE_FORMAT)
                return status_df
        except Exception as e:
            st.error(f"åŠ è½½ç‰©æµçŠ¶æ€æ–‡ä»¶å¤±è´¥: {str(e)}")
            return pd.DataFrame(columns=["record_id", "åˆ°è´§çŠ¶æ€", "ç‰©æµä¿¡æ¯", "update_time"])
    return pd.DataFrame(columns=["record_id", "åˆ°è´§çŠ¶æ€", "ç‰©æµä¿¡æ¯", "update_time"])


def save_logistics_status(status_df):
    try:
        with st.spinner("ä¿å­˜çŠ¶æ€..."):
            status_df.to_csv(AppConfig.LOGISTICS_STATUS_FILE, index=False, encoding='utf-8-sig')
            return True
    except Exception as e:
        st.error(f"çŠ¶æ€ä¿å­˜å¤±è´¥: {str(e)}")
        return False


def merge_logistics_with_status(logistics_df):
    if logistics_df.empty:
        return logistics_df

    status_df = load_logistics_status()
    if status_df.empty:
        logistics_df["åˆ°è´§çŠ¶æ€"] = "å…¬å¸ç»Ÿç­¹ä¸­"  # é»˜è®¤çŠ¶æ€
        logistics_df["ç‰©æµä¿¡æ¯"] = ""  # æ–°å¢ç‰©æµä¿¡æ¯åˆ—
        return logistics_df

    merged = pd.merge(
        logistics_df,
        status_df[["record_id", "åˆ°è´§çŠ¶æ€", "ç‰©æµä¿¡æ¯"]],
        on="record_id",
        how="left",
        suffixes=("", "_status")
    )
    # å¡«å……ç¼ºå¤±å€¼
    merged["åˆ°è´§çŠ¶æ€"] = merged["åˆ°è´§çŠ¶æ€_status"].fillna("å…¬å¸ç»Ÿç­¹ä¸­")
    merged["ç‰©æµä¿¡æ¯"] = merged["ç‰©æµä¿¡æ¯_status"].fillna("")
    return merged.drop(columns=["åˆ°è´§çŠ¶æ€_status", "ç‰©æµä¿¡æ¯_status"])


def update_logistics_status(record_id, new_status, logistics_info="", original_row=None):
    """æ›´æ–°ç‰©æµçŠ¶æ€å’Œç‰©æµä¿¡æ¯ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰"""
    try:
        status_df = load_logistics_status()

        if new_status is None:
            new_status = "å…¬å¸ç»Ÿç­¹ä¸­"  # é»˜è®¤çŠ¶æ€
        new_status = str(new_status).strip()
        
        if logistics_info is None:
            logistics_info = ""
        logistics_info = str(logistics_info).strip()

        send_notification = False
        if new_status == "æœªåˆ°è´§":
            existing_status = status_df.loc[status_df["record_id"] == record_id, "åˆ°è´§çŠ¶æ€"]
            if len(existing_status) == 0 or existing_status.iloc[0] != "æœªåˆ°è´§":
                send_notification = True

        if record_id in status_df["record_id"].values:
            if new_status == "":
                status_df = status_df[status_df["record_id"] != record_id]
            else:
                status_df.loc[status_df["record_id"] == record_id, "åˆ°è´§çŠ¶æ€"] = new_status
                status_df.loc[status_df["record_id"] == record_id, "ç‰©æµä¿¡æ¯"] = logistics_info
                status_df.loc[status_df["record_id"] == record_id, "update_time"] = datetime.now().strftime(
                    AppConfig.DATE_FORMAT)
        elif new_status != "":
            new_record = pd.DataFrame([{
                "record_id": record_id,
                "åˆ°è´§çŠ¶æ€": new_status,
                "ç‰©æµä¿¡æ¯": logistics_info,
                "update_time": datetime.now().strftime(AppConfig.DATE_FORMAT)
            }])
            status_df = pd.concat([status_df, new_record], ignore_index=True)

        if save_logistics_status(status_df):
            if send_notification and original_row is not None:
                material_info = {
                    "ç‰©èµ„åç§°": original_row["ç‰©èµ„åç§°"],
                    "è§„æ ¼å‹å·": original_row["è§„æ ¼å‹å·"],
                    "æ•°é‡": original_row["æ•°é‡"],
                    "äº¤è´§æ—¶é—´": original_row["äº¤è´§æ—¶é—´"].strftime("%Y-%m-%d %H:%M") if pd.notna(
                        original_row["äº¤è´§æ—¶é—´"]) else "æœªçŸ¥",
                    "é¡¹ç›®éƒ¨": original_row["é¡¹ç›®éƒ¨"]
                }
                if send_feishu_notification(material_info):
                    st.toast("å·²å‘é€ç‰©æµå¼‚å¸¸é€šçŸ¥åˆ°ç›¸å…³è´Ÿè´£äºº", icon="ğŸ“¨")
            return True
        return False

    except Exception as e:
        st.error(f"æ›´æ–°çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
        return False


# ==================== é¡µé¢ç»„ä»¶ ====================
def show_logistics_tab(project):
    # æ—¥æœŸé€‰æ‹©å™¨å¸ƒå±€è°ƒæ•´
    date_col1, date_col2 = st.columns(2)
    with date_col1:
        logistics_start_date = st.date_input(
            "å¼€å§‹æ—¥æœŸ",
            datetime.now().date() - timedelta(days=AppConfig.LOGISTICS_DATE_RANGE_DAYS),
            key="logistics_start"
        )
    with date_col2:
        logistics_end_date = st.date_input(
            "ç»“æŸæ—¥æœŸ",
            datetime.now().date(),
            key="logistics_end"
        )

    if logistics_start_date > logistics_end_date:
        st.error("ç»“æŸæ—¥æœŸä¸èƒ½æ—©äºå¼€å§‹æ—¥æœŸ")
        return

    with st.spinner("åŠ è½½ç‰©æµä¿¡æ¯..."):
        logistics_df = load_logistics_data()
        if project != "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸":
            logistics_df = logistics_df[logistics_df["é¡¹ç›®éƒ¨"] == project]

        if not logistics_df.empty:
            logistics_df = merge_logistics_with_status(logistics_df)

            # ä¿®å¤æ—¥æœŸæ¯”è¾ƒé—®é¢˜ - ç¡®ä¿ç±»å‹ä¸€è‡´
            start_date_pd = pd.to_datetime(logistics_start_date)
            end_date_pd = pd.to_datetime(logistics_end_date) + timedelta(days=1)  # åŒ…å«ç»“æŸæ—¥æœŸçš„å…¨å¤©

            mask = (
                    (logistics_df["äº¤è´§æ—¶é—´"] >= start_date_pd) &
                    (logistics_df["äº¤è´§æ—¶é—´"] < end_date_pd)
            )
            filtered_df = logistics_df[mask].copy()

            # =============== ç»Ÿä¸€å¡ç‰‡æ ·å¼ ===============
            st.markdown('<div class="metric-container">', unsafe_allow_html=True)

            total_count = len(filtered_df)
            arrived_count = len(filtered_df[filtered_df['åˆ°è´§çŠ¶æ€'] == 'å·²åˆ°è´§'])
            not_arrived_count = len(filtered_df[filtered_df['åˆ°è´§çŠ¶æ€'] == 'æœªåˆ°è´§'])
            coordinating_count = len(filtered_df[filtered_df['åˆ°è´§çŠ¶æ€'] == 'å…¬å¸ç»Ÿç­¹ä¸­'])
            accepted_count = len(filtered_df[filtered_df['åˆ°è´§çŠ¶æ€'] == 'é’¢å‚å·²æ¥å•'])
            transporting_count = len(filtered_df[filtered_df['åˆ°è´§çŠ¶æ€'] == 'è¿è¾“ä¸­'])

            cols = st.columns(5)
            metrics = [
                ("ğŸ“¦", "æ€»ç‰©æµå•æ•°", f"{total_count}", "å•"),
                ("ğŸ¢", "å…¬å¸ç»Ÿç­¹ä¸­", f"{coordinating_count}", "å•"),
                ("âœ…", "é’¢å‚å·²æ¥å•", f"{accepted_count}", "å•"),
                ("ğŸšš", "è¿è¾“ä¸­", f"{transporting_count}", "å•"),
                ("ğŸ“¬", "å·²åˆ°è´§", f"{arrived_count}", "å•")
            ]

            for idx, metric in enumerate(metrics):
                with cols[idx]:
                    st.markdown(f"""
                    <div class="metric-card">
                        <div style="display:flex; align-items:center; gap:0.5rem;">
                            <span style="font-size:1.2rem">{metric[0]}</span>
                            <span style="font-weight:600">{metric[1]}</span>
                        </div>
                        <div class="card-value">{metric[2]}</div>
                        <div class="card-unit">{metric[3]}</div>
                    </div>
                    """, unsafe_allow_html=True)

            st.markdown('</div>', unsafe_allow_html=True)

            st.caption(f"æ˜¾ç¤º {logistics_start_date} è‡³ {logistics_end_date} çš„æ•°æ®ï¼ˆå…± {len(filtered_df)} æ¡è®°å½•ï¼‰")

            # å‡†å¤‡æ˜¾ç¤ºçš„åˆ—ï¼ˆæ’é™¤record_idï¼‰
            display_columns = [col for col in filtered_df.columns if col != "record_id"]
            display_df = filtered_df[display_columns].copy()

            # é‡ç½®ç´¢å¼•ä»¥ç¡®ä¿ä¸€è‡´æ€§
            display_df = display_df.reset_index(drop=True)

            # ä½¿ç”¨è‡ªåŠ¨ä¿å­˜çš„æ•°æ®ç¼–è¾‘å™¨
            st.markdown("**ç‰©æµæ˜ç»†è¡¨** (çŠ¶æ€æ›´æ”¹ä¼šè‡ªåŠ¨ä¿å­˜)")
            edited_df = st.data_editor(
                display_df,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "åˆ°è´§çŠ¶æ€": st.column_config.SelectboxColumn(
                        "åˆ°è´§çŠ¶æ€",
                        options=AppConfig.STATUS_OPTIONS,
                        default="å…¬å¸ç»Ÿç­¹ä¸­",  # è®¾ç½®é»˜è®¤çŠ¶æ€
                        required=True,
                        width="medium"
                    ),
                    "æ•°é‡": st.column_config.NumberColumn(
                        "æ•°é‡",
                        format="%d",
                        width=100  # è®¾ç½®æ•°é‡åˆ—å®½ä¸º10ä¸ªå­—ç¬¦å®½åº¦
                    ),
                    "ç‰©æµä¿¡æ¯": st.column_config.TextColumn(
                        "ç‰©æµä¿¡æ¯",
                        width="large",  # ç‰©æµä¿¡æ¯åˆ—å¯ä»¥å®½ä¸€äº›
                        help="å¯è¾“å…¥ç‰©æµè·Ÿè¸ªå·ã€å¤‡æ³¨ç­‰ä¿¡æ¯"
                    ),
                    "äº¤è´§æ—¶é—´": st.column_config.DatetimeColumn(
                        "äº¤è´§æ—¶é—´",
                        format="YYYY-MM-DD HH:mm",
                        width="medium"
                    ),
                    **{col: {"width": "auto"} for col in display_columns if
                       col not in ["åˆ°è´§çŠ¶æ€", "æ•°é‡", "ç‰©æµä¿¡æ¯", "äº¤è´§æ—¶é—´"]}
                },
                key=f"logistics_editor_{project}"
            )

            # è‡ªåŠ¨å¤„ç†çŠ¶æ€æ›´æ”¹
            auto_process_logistics_changes(edited_df, filtered_df, project)

            st.markdown("""
            <div class="remark-card logistics-remark">
                <div class="remark-content">
                    ğŸ“¢ ä»¥ä¸Šæ•°æ®ä¸ºå…¬å¸å·²å®‰æ’çš„å‘è´§æƒ…å†µ
                </div>
            </div>
            """, unsafe_allow_html=True)

            status_df = load_logistics_status()
            if not status_df.empty:
                last_update = pd.to_datetime(status_df["update_time"]).max()
                st.caption(f"çŠ¶æ€æœ€åæ›´æ–°æ—¶é—´: {last_update.strftime('%Y-%m-%d %H:%M:%S')}")
        else:
            st.info("ğŸ“­ å½“å‰æ²¡æœ‰ç‰©æµæ•°æ®")


def auto_process_logistics_changes(edited_df, original_filtered_df, project):
    """è‡ªåŠ¨å¤„ç†ç‰©æµçŠ¶æ€æ›´æ”¹"""
    if f'logistics_editor_{project}' not in st.session_state:
        return

    changed_rows = st.session_state[f'logistics_editor_{project}'].get('edited_rows', {})

    if not changed_rows:
        return

    # ä½¿ç”¨session_stateè®°å½•å·²å¤„ç†çš„æ›´æ”¹ï¼Œé¿å…é‡å¤å¤„ç†
    processed_key = f"processed_changes_{project}"
    if processed_key not in st.session_state:
        st.session_state[processed_key] = set()

    # å¤„ç†æ–°çš„æ›´æ”¹
    new_changes = []
    for row_index_str, changes in changed_rows.items():
        change_hash = f"{row_index_str}_{changes.get('åˆ°è´§çŠ¶æ€', '')}_{changes.get('ç‰©æµä¿¡æ¯', '')}"
        if change_hash not in st.session_state[processed_key]:
            new_changes.append((row_index_str, changes))
            st.session_state[processed_key].add(change_hash)

    if not new_changes:
        return

    # å¤„ç†æ–°çš„æ›´æ”¹
    success_count = 0
    error_count = 0

    for row_index_str, changes in new_changes:
        try:
            # ç¡®ä¿è¡Œç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
            row_index = int(row_index_str)
            if row_index < 0 or row_index >= len(original_filtered_df):
                st.warning(f"è·³è¿‡æ— æ•ˆçš„è¡Œç´¢å¼•: {row_index}")
                error_count += 1
                continue

            # è·å–åŸå§‹è¡Œæ•°æ®
            original_row = original_filtered_df.iloc[row_index]
            record_id = original_row["record_id"]

            # è·å–æ›´æ”¹åçš„çŠ¶æ€å’Œç‰©æµä¿¡æ¯
            new_status = changes.get("åˆ°è´§çŠ¶æ€", original_row["åˆ°è´§çŠ¶æ€"])
            new_logistics_info = changes.get("ç‰©æµä¿¡æ¯", original_row.get("ç‰©æµä¿¡æ¯", ""))

            # è·å–å½“å‰çŠ¶æ€å’Œç‰©æµä¿¡æ¯
            current_status = original_row["åˆ°è´§çŠ¶æ€"]
            current_logistics_info = original_row.get("ç‰©æµä¿¡æ¯", "")

            # åªæœ‰å½“çŠ¶æ€æˆ–ç‰©æµä¿¡æ¯çœŸæ­£æ”¹å˜æ—¶æ‰æ›´æ–°
            if new_status != current_status or new_logistics_info != current_logistics_info:
                # æ›´æ–°çŠ¶æ€
                if update_logistics_status(record_id, new_status, new_logistics_info, original_row):
                    success_count += 1
                    # ä½¿ç”¨toastæ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                    status_msg = f"çŠ¶æ€: {new_status}" if new_status != current_status else ""
                    info_msg = f"ç‰©æµä¿¡æ¯å·²æ›´æ–°" if new_logistics_info != current_logistics_info else ""
                    msg = " | ".join([part for part in [status_msg, info_msg] if part])
                    if msg:
                        st.toast(f"âœ… {original_row['ç‰©èµ„åç§°']} - {msg}", icon="âœ…")
                else:
                    error_count += 1
                    st.toast(f"âŒ ä¿å­˜å¤±è´¥: {original_row['ç‰©èµ„åç§°']}", icon="âŒ")

        except (ValueError, KeyError, IndexError) as e:
            st.warning(f"å¤„ç†è¡Œ {row_index_str} æ—¶å‡ºé”™: {str(e)}")
            error_count += 1
            continue

    # æ˜¾ç¤ºå¤„ç†ç»“æœæ‘˜è¦
    if success_count > 0:
        # ä½¿ç”¨æˆåŠŸæ¶ˆæ¯ä½†ä¸é˜»å¡ç•Œé¢
        st.success(f"å·²è‡ªåŠ¨ä¿å­˜ {success_count} æ¡æ›´æ”¹")

        # 3ç§’åæ¸…é™¤æˆåŠŸæ¶ˆæ¯
        time.sleep(3)
        st.empty()

    if error_count > 0:
        st.error(f"æœ‰ {error_count} æ¡è®°å½•ä¿å­˜å¤±è´¥")


def display_metrics_cards(filtered_df):
    if filtered_df.empty:
        return

    total = int(filtered_df["éœ€æ±‚é‡"].sum())
    shipped = int(filtered_df["å·²å‘é‡"].sum())
    pending = int(filtered_df["å‰©ä½™é‡"].sum())
    overdue = len(filtered_df[filtered_df["è¶…æœŸå¤©æ•°"] > 0])
    max_overdue = filtered_df["è¶…æœŸå¤©æ•°"].max() if overdue > 0 else 0

    st.markdown('<div class="metric-container">', unsafe_allow_html=True)
    cols = st.columns(4)
    metrics = [
        ("ğŸ“¦", "æ€»éœ€æ±‚é‡", f"{total:,}", "å¨", "total"),
        ("ğŸšš", "å·²å‘è´§é‡", f"{shipped:,}", "å¨", "shipped"),
        ("â³", "å¾…å‘è´§é‡", f"{pending:,}", "å¨", "pending"),
        ("âš ï¸", "è¶…æœŸè®¢å•", f"{overdue}", "å•", "overdue", f"æœ€å¤§è¶…æœŸ: {max_overdue}å¤©" if overdue > 0 else "")
    ]

    for idx, metric in enumerate(metrics):
        with cols[idx]:
            st.markdown(f"""
            <div class="metric-card {metric[4]}">
                <div style="display:flex; align-items:center; gap:0.5rem;">
                    <span style="font-size:1.2rem">{metric[0]}</span>
                    <span style="font-weight:600">{metric[1]}</span>
                </div>
                <div class="card-value">{metric[2]}</div>
                <div class="card-unit">{metric[3]}</div>
                {f'<div style="font-size:0.8rem; color:#666;">{metric[5]}</div>' if len(metric) > 5 else ''}
            </div>
            """, unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)


def show_data_panel(df, project):
    st.title(f"{project} - å‘è´§æ•°æ®")

    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
        with st.spinner("åˆ·æ–°æ•°æ®ä¸­..."):
            st.cache_data.clear()
            st.rerun()

    tab1, tab2 = st.tabs(["ğŸ“‹ å‘è´§è®¡åˆ’", "ğŸš› ç‰©æµæ˜ç»†"])

    with tab1:
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("å¼€å§‹æ—¥æœŸ", datetime.now() - timedelta(days=0))
        with col2:
            end_date = st.date_input("ç»“æŸæ—¥æœŸ", datetime.now())

        if start_date > end_date:
            st.error("æ—¥æœŸèŒƒå›´æ— æ•ˆ")
        else:
            with st.spinner("ç­›é€‰æ•°æ®..."):
                filtered_df = df if project == "ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸" else df[df[AppConfig.PROJECT_COLUMN] == project]
                date_range_df = filtered_df[
                    (filtered_df["ä¸‹å•æ—¶é—´"].dt.date >= start_date) &
                    (filtered_df["ä¸‹å•æ—¶é—´"].dt.date <= end_date)
                    ]

                if not date_range_df.empty:
                    display_metrics_cards(date_range_df)

                    display_cols = {
                        "æ ‡æ®µåç§°": "å·¥ç¨‹æ ‡æ®µ",
                        "ç‰©èµ„åç§°": "ææ–™åç§°",
                        "è§„æ ¼å‹å·": "è§„æ ¼å‹å·",
                        "éœ€æ±‚é‡": "éœ€æ±‚(å¨)",
                        "å·²å‘é‡": "å·²å‘(å¨)",
                        "å‰©ä½™é‡": "å¾…å‘(å¨)",
                        "è¶…æœŸå¤©æ•°": "è¶…æœŸå¤©æ•°",
                        "ä¸‹å•æ—¶é—´": "ä¸‹å•æ—¶é—´",
                        "è®¡åˆ’è¿›åœºæ—¶é—´": "è®¡åˆ’è¿›åœºæ—¶é—´"
                    }

                    available_cols = {k: v for k, v in display_cols.items() if k in date_range_df.columns}
                    display_df = date_range_df[available_cols.keys()].rename(columns=available_cols)

                    if "ææ–™åç§°" in display_df.columns:
                        display_df["ææ–™åç§°"] = display_df["ææ–™åç§°"].fillna("æœªæŒ‡å®šç‰©èµ„")

                    st.dataframe(
                        display_df.style.format({
                            'éœ€æ±‚(å¨)': '{:,}',
                            'å·²å‘(å¨)': '{:,}',
                            'å¾…å‘(å¨)': '{:,}',
                            'è¶…æœŸå¤©æ•°': '{:,}',
                            'ä¸‹å•æ—¶é—´': lambda x: x.strftime('%Y-%m-%d') if not pd.isnull(x) else '',
                            'è®¡åˆ’è¿›åœºæ—¶é—´': lambda x: x.strftime('%Y-%m-%d') if not pd.isnull(x) else ''
                        }).apply(
                            lambda row: ['background-color: #ffdddd' if row.get('è¶…æœŸå¤©æ•°', 0) > 0 else ''
                                         for _ in row],
                            axis=1
                        ),
                        use_container_width=True,
                        height=min(600, 35 * len(display_df) + 40),
                        hide_index=True
                    )

                    st.markdown("""
                    <div class="remark-card plan-remark">
                        <div class="remark-content">
                            ğŸ“¢ ä»¥ä¸Šè®¡åˆ’å·²å…¨éƒ¨ææŠ¥ç»™å…¬å¸
                        </div>
                    </div>
                    """, unsafe_allow_html=True)

                    st.download_button(
                        "â¬‡ï¸ å¯¼å‡ºæ•°æ®",
                        display_df.to_csv(index=False).encode('utf-8-sig'),
                        f"{project}_å‘è´§æ•°æ®_{start_date}_{end_date}.csv",
                        "text/csv",
                        use_container_width=True
                    )
                else:
                    st.info("è¯¥æ—¶é—´æ®µæ— æ•°æ®")

    with tab2:
        show_logistics_tab(project)


# ==================== ä¸»ç¨‹åº ====================
def main():
    st.set_page_config(
        layout="wide",
        page_title="é’¢ç­‹å‘è´§ç›‘æ§ç³»ç»Ÿ",
        page_icon="ğŸ—ï¸",
        initial_sidebar_state="expanded"
    )
    apply_card_styles()

    # ä»URLå‚æ•°è·å–é¡¹ç›®åç§°
    query_params = st.experimental_get_query_params()
    project_name = query_params.get("project", ["ä¸­é“ç‰©è´¸æˆéƒ½åˆ†å…¬å¸"])[0]
    
    # è®¾ç½®é»˜è®¤é¡¹ç›®
    if 'selected_project' not in st.session_state:
        st.session_state.selected_project = project_name

    with st.spinner('åŠ è½½æ•°æ®ä¸­...'):
        df = load_data()

    # ç›´æ¥æ˜¾ç¤ºæ•°æ®é¢æ¿ï¼Œæ— éœ€é€‰æ‹©
    show_data_panel(df, st.session_state.selected_project)


if __name__ == "__main__":
    main()
